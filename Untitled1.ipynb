{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from os.path import abspath, dirname, join\n",
    "import numpy as np\n",
    "from skimage.color import grey2rgb\n",
    "from skimage.io import imread\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from detection import choice_permutation, read_generator, pad_and_scale"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from os.path import abspath, dirname, join\n",
    "import numpy as np\n",
    "from skimage.color import grey2rgb, rgb2grey\n",
    "from skimage.io import imread\n",
    "from tqdm import tqdm\n",
    "from keras import backend as K\n",
    "from keras.models import load_model, save_model,  Sequential\n",
    "from keras.layers import Dense, Dropout, Activation, Conv2D, MaxPooling2D,Flatten, Convolution2D, BatchNormalization\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.optimizers import RMSprop, Adam, Adadelta\n",
    "from keras.callbacks import ModelCheckpoint, EarlyStopping, ReduceLROnPlateau\n",
    "from keras.optimizers import SGD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def read_test(y, img_dir):\n",
    "    test = np.zeros(( len(y), 100, 100, 1))\n",
    "    y_test = np.zeros((len(y), 28))\n",
    "    for i, img_name in tqdm(enumerate(y.keys()), total=len(y)):\n",
    "        img = imread(join(img_dir, img_name), as_grey=True)\n",
    "        img, points = pad_and_scale(img, y[img_name])\n",
    "        \n",
    "        test[i, ...] = img.reshape((100, 100, 1))\n",
    "        y_test[i] = np.ravel(points, order='F')\n",
    "\n",
    "    return y_test, test\n",
    "\n",
    "def read(y, train_img_dir):\n",
    "    \"\"\"\n",
    "\n",
    "    :type y: dict\n",
    "    \"\"\"\n",
    "    train = np.zeros(( len(y), 1, 100, 100))\n",
    "    y_train = np.zeros((len(y), 28))\n",
    "    for i, img_name in tqdm(enumerate(y.keys()), total=len(y)):\n",
    "        img = imread(join(train_img_dir, img_name), as_grey=True)\n",
    "        \n",
    "        train[i, ...] = img.reshape(100, 100, 1)\n",
    "        y_train[i] = np.array(y[img_name])\n",
    "\n",
    "    return y_train, train\n",
    "\n",
    "def generator(labels, batch_size, train_img_dir):\n",
    "    batch_features = np.zeros((batch_size, 100,100, 3))\n",
    "    batch_labels = np.zeros((batch_size,28))\n",
    "    \n",
    "    img_names = list(labels.keys())\n",
    "    np.random.shuffle(img_names)\n",
    "    \n",
    "    while True:\n",
    "        for img_name in img_names:\n",
    "            for i in range(batch_size):\n",
    "                img = imread(join(train_img_dir, img_name))\n",
    "                \n",
    "                if len(img.shape) < 3:\n",
    "                    img = grey2rgb(img)\n",
    "                \n",
    "                batch_features[i, ...] = img\n",
    "                batch_labels[i] = np.array(labels[img_name])\n",
    "            \n",
    "            yield batch_features, batch_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from preprocessing import read_csv\n",
    "csv = read_csv('./public_data/00_input/train/gt.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 12000/12000 [00:22<00:00, 532.91it/s]\n"
     ]
    }
   ],
   "source": [
    "y_train, train = read(csv, './__temp')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train = (train - train.mean(axis=0)) / train.std(axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from random import choice\n",
    "names = list(csv.keys())\n",
    "names_test = np.random.choice(names, int(0.2 * len(names)))\n",
    "\n",
    "train_csv = {name: csv[name] for name in csv if name not in names_test}\n",
    "test_csv = {name: csv[name] for name in names_test}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "test_csv['00002.jpg'] = train_csv['00002.jpg']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████| 1069/1069 [00:19<00:00, 55.75it/s]\n"
     ]
    }
   ],
   "source": [
    "y_test, test = read_test(test_csv, './public_data/00_input/train/images')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/300\n",
      "200/200 [==============================] - 116s - loss: 346.6573 - val_loss: 304.5151\n",
      "Epoch 2/300\n",
      "200/200 [==============================] - 113s - loss: 116.0300 - val_loss: 307.0756\n",
      "Epoch 3/300\n",
      "200/200 [==============================] - 117s - loss: 111.1847 - val_loss: 215.8196\n",
      "Epoch 4/300\n",
      "200/200 [==============================] - 121s - loss: 104.2088 - val_loss: 221.6601\n",
      "Epoch 5/300\n",
      "200/200 [==============================] - 123s - loss: 107.7671 - val_loss: 194.7184\n",
      "Epoch 6/300\n",
      "200/200 [==============================] - 126s - loss: 104.2080 - val_loss: 158.0500\n",
      "Epoch 7/300\n",
      "200/200 [==============================] - 129s - loss: 101.5254 - val_loss: 90.5821\n",
      "Epoch 8/300\n",
      "200/200 [==============================] - 135s - loss: 105.4905 - val_loss: 45.3994\n",
      "Epoch 9/300\n",
      "200/200 [==============================] - 130s - loss: 105.9053 - val_loss: 35.7135\n",
      "Epoch 10/300\n",
      "200/200 [==============================] - 131s - loss: 74.0427 - val_loss: 24.9416\n",
      "Epoch 11/300\n",
      "200/200 [==============================] - 129s - loss: 42.3733 - val_loss: 22.1371\n",
      "Epoch 12/300\n",
      "200/200 [==============================] - 128s - loss: 35.8863 - val_loss: 24.9268\n",
      "Epoch 13/300\n",
      "200/200 [==============================] - 136s - loss: 31.2230 - val_loss: 18.1411\n",
      "Epoch 14/300\n",
      "200/200 [==============================] - 138s - loss: 28.0829 - val_loss: 19.6344\n",
      "Epoch 15/300\n",
      "200/200 [==============================] - 131s - loss: 28.0767 - val_loss: 17.1356\n",
      "Epoch 16/300\n",
      "200/200 [==============================] - 131s - loss: 27.2055 - val_loss: 13.7053\n",
      "Epoch 17/300\n",
      "200/200 [==============================] - 131s - loss: 25.6584 - val_loss: 13.7884\n",
      "Epoch 18/300\n",
      "200/200 [==============================] - 133s - loss: 25.3601 - val_loss: 15.6656\n",
      "Epoch 19/300\n",
      "200/200 [==============================] - 121s - loss: 23.0937 - val_loss: 12.4133\n",
      "Epoch 20/300\n",
      "200/200 [==============================] - 126s - loss: 21.9661 - val_loss: 10.9812\n",
      "Epoch 21/300\n",
      "200/200 [==============================] - 118s - loss: 22.3737 - val_loss: 12.1757\n",
      "Epoch 22/300\n",
      "200/200 [==============================] - 119s - loss: 23.1067 - val_loss: 10.7326\n",
      "Epoch 23/300\n",
      "200/200 [==============================] - 121s - loss: 22.4271 - val_loss: 11.5164\n",
      "Epoch 24/300\n",
      "200/200 [==============================] - 127s - loss: 21.5004 - val_loss: 11.6112\n",
      "Epoch 25/300\n",
      "200/200 [==============================] - 132s - loss: 20.7906 - val_loss: 10.6844\n",
      "Epoch 26/300\n",
      "200/200 [==============================] - 127s - loss: 21.5766 - val_loss: 10.8745\n",
      "Epoch 27/300\n",
      "200/200 [==============================] - 131s - loss: 20.2985 - val_loss: 9.8011\n",
      "Epoch 28/300\n",
      "200/200 [==============================] - 135s - loss: 20.2347 - val_loss: 10.5605\n",
      "Epoch 29/300\n",
      "200/200 [==============================] - 122s - loss: 19.6077 - val_loss: 10.7182\n",
      "Epoch 30/300\n",
      "200/200 [==============================] - 136s - loss: 18.8647 - val_loss: 9.8977\n",
      "Epoch 31/300\n",
      "200/200 [==============================] - 122s - loss: 18.3980 - val_loss: 9.5171\n",
      "Epoch 32/300\n",
      "200/200 [==============================] - 127s - loss: 18.3809 - val_loss: 9.9635\n",
      "Epoch 33/300\n",
      "200/200 [==============================] - 125s - loss: 17.4577 - val_loss: 11.2010\n",
      "Epoch 34/300\n",
      "200/200 [==============================] - 127s - loss: 17.5253 - val_loss: 8.4300\n",
      "Epoch 35/300\n",
      "200/200 [==============================] - 131s - loss: 18.1955 - val_loss: 8.7854\n",
      "Epoch 36/300\n",
      "200/200 [==============================] - 122s - loss: 16.6571 - val_loss: 8.1990\n",
      "Epoch 37/300\n",
      "200/200 [==============================] - 131s - loss: 17.5674 - val_loss: 7.9212\n",
      "Epoch 38/300\n",
      "200/200 [==============================] - 124s - loss: 15.2291 - val_loss: 7.9271\n",
      "Epoch 39/300\n",
      "200/200 [==============================] - 132s - loss: 13.9479 - val_loss: 7.7249\n",
      "Epoch 40/300\n",
      "200/200 [==============================] - 125s - loss: 14.3815 - val_loss: 10.9206\n",
      "Epoch 41/300\n",
      "200/200 [==============================] - 135s - loss: 15.8933 - val_loss: 7.5338\n",
      "Epoch 42/300\n",
      "200/200 [==============================] - 138s - loss: 15.2380 - val_loss: 8.4955\n",
      "Epoch 43/300\n",
      "200/200 [==============================] - 124s - loss: 14.0198 - val_loss: 7.1944\n",
      "Epoch 44/300\n",
      "200/200 [==============================] - 129s - loss: 15.4721 - val_loss: 7.9209\n",
      "Epoch 45/300\n",
      "200/200 [==============================] - 125s - loss: 13.7121 - val_loss: 6.8085\n",
      "Epoch 46/300\n",
      "200/200 [==============================] - 132s - loss: 13.3600 - val_loss: 7.0523\n",
      "Epoch 47/300\n",
      "200/200 [==============================] - 123s - loss: 13.5694 - val_loss: 7.5891\n",
      "Epoch 48/300\n",
      "200/200 [==============================] - 119s - loss: 12.3771 - val_loss: 7.0153\n",
      "Epoch 49/300\n",
      "200/200 [==============================] - 129s - loss: 12.1857 - val_loss: 7.5593\n",
      "Epoch 50/300\n",
      "200/200 [==============================] - 129s - loss: 12.5614 - val_loss: 6.6837\n",
      "Epoch 51/300\n",
      "200/200 [==============================] - 121s - loss: 12.4927 - val_loss: 6.2755\n",
      "Epoch 52/300\n",
      "200/200 [==============================] - 120s - loss: 11.5642 - val_loss: 6.9686\n",
      "Epoch 53/300\n",
      "200/200 [==============================] - 124s - loss: 11.6887 - val_loss: 7.1147\n",
      "Epoch 54/300\n",
      "200/200 [==============================] - 126s - loss: 11.6275 - val_loss: 7.8700\n",
      "Epoch 55/300\n",
      "200/200 [==============================] - 131s - loss: 11.6441 - val_loss: 6.2216\n",
      "Epoch 56/300\n",
      "200/200 [==============================] - 137s - loss: 10.2780 - val_loss: 5.9950\n",
      "Epoch 57/300\n",
      "200/200 [==============================] - 133s - loss: 10.2808 - val_loss: 5.9064\n",
      "Epoch 58/300\n",
      "200/200 [==============================] - 130s - loss: 10.4100 - val_loss: 6.4730\n",
      "Epoch 59/300\n",
      "200/200 [==============================] - 124s - loss: 10.1301 - val_loss: 6.0173\n",
      "Epoch 60/300\n",
      "200/200 [==============================] - 126s - loss: 10.3640 - val_loss: 6.6129\n",
      "Epoch 61/300\n",
      "200/200 [==============================] - 129s - loss: 10.0427 - val_loss: 5.6841\n",
      "Epoch 62/300\n",
      "200/200 [==============================] - 128s - loss: 10.1332 - val_loss: 5.4196\n",
      "Epoch 63/300\n",
      "200/200 [==============================] - 128s - loss: 9.3216 - val_loss: 5.7020\n",
      "Epoch 64/300\n",
      "200/200 [==============================] - 126s - loss: 9.3492 - val_loss: 5.4190\n",
      "Epoch 65/300\n",
      "200/200 [==============================] - 129s - loss: 8.7603 - val_loss: 5.1124\n",
      "Epoch 66/300\n",
      "200/200 [==============================] - 127s - loss: 8.8595 - val_loss: 6.2785\n",
      "Epoch 67/300\n",
      "200/200 [==============================] - 117s - loss: 7.8763 - val_loss: 5.1754\n",
      "Epoch 68/300\n",
      "200/200 [==============================] - 124s - loss: 8.5789 - val_loss: 5.6489\n",
      "Epoch 69/300\n",
      "200/200 [==============================] - 120s - loss: 8.5482 - val_loss: 5.2860\n",
      "Epoch 70/300\n",
      "200/200 [==============================] - 121s - loss: 8.3427 - val_loss: 4.9521\n",
      "Epoch 71/300\n",
      "200/200 [==============================] - 123s - loss: 7.3657 - val_loss: 5.0315\n",
      "Epoch 72/300\n",
      "200/200 [==============================] - 124s - loss: 8.1928 - val_loss: 6.1219\n",
      "Epoch 73/300\n",
      "200/200 [==============================] - 122s - loss: 7.9436 - val_loss: 5.6863\n",
      "Epoch 74/300\n",
      "200/200 [==============================] - 122s - loss: 8.1866 - val_loss: 4.9885\n",
      "Epoch 75/300\n",
      "200/200 [==============================] - 124s - loss: 8.2360 - val_loss: 5.0222\n",
      "Epoch 76/300\n",
      "200/200 [==============================] - 123s - loss: 8.3195 - val_loss: 5.7114\n",
      "Epoch 77/300\n",
      "200/200 [==============================] - 117s - loss: 8.0302 - val_loss: 5.0349\n",
      "Epoch 78/300\n",
      "200/200 [==============================] - 125s - loss: 7.6841 - val_loss: 4.7355\n",
      "Epoch 79/300\n",
      "200/200 [==============================] - 121s - loss: 7.8771 - val_loss: 4.6457\n",
      "Epoch 80/300\n",
      "200/200 [==============================] - 124s - loss: 7.0343 - val_loss: 4.6639\n",
      "Epoch 81/300\n",
      "200/200 [==============================] - 122s - loss: 6.8572 - val_loss: 4.5228\n",
      "Epoch 82/300\n",
      "200/200 [==============================] - 125s - loss: 7.5148 - val_loss: 4.5219\n",
      "Epoch 83/300\n",
      "200/200 [==============================] - 118s - loss: 6.3785 - val_loss: 4.4569\n",
      "Epoch 84/300\n",
      "200/200 [==============================] - 129s - loss: 7.0069 - val_loss: 4.3839\n",
      "Epoch 85/300\n",
      "200/200 [==============================] - 122s - loss: 6.6301 - val_loss: 4.3986\n",
      "Epoch 86/300\n",
      "200/200 [==============================] - 118s - loss: 6.7741 - val_loss: 4.4102\n",
      "Epoch 87/300\n",
      "200/200 [==============================] - 125s - loss: 6.7492 - val_loss: 4.3557\n",
      "Epoch 88/300\n",
      "200/200 [==============================] - 125s - loss: 6.7705 - val_loss: 4.4272\n",
      "Epoch 89/300\n",
      "200/200 [==============================] - 119s - loss: 6.4843 - val_loss: 4.3488\n",
      "Epoch 90/300\n",
      "200/200 [==============================] - 123s - loss: 6.5340 - val_loss: 4.3355\n",
      "Epoch 91/300\n",
      "200/200 [==============================] - 121s - loss: 6.9696 - val_loss: 4.2486\n",
      "Epoch 92/300\n",
      "200/200 [==============================] - 122s - loss: 6.7723 - val_loss: 4.2137\n",
      "Epoch 93/300\n",
      "200/200 [==============================] - 124s - loss: 6.2891 - val_loss: 4.2316\n",
      "Epoch 94/300\n",
      "200/200 [==============================] - 122s - loss: 6.2110 - val_loss: 4.1684\n",
      "Epoch 95/300\n",
      "200/200 [==============================] - 127s - loss: 6.3429 - val_loss: 4.1860\n",
      "Epoch 96/300\n",
      "200/200 [==============================] - 123s - loss: 6.0774 - val_loss: 4.1787\n",
      "Epoch 97/300\n",
      "200/200 [==============================] - 126s - loss: 6.4618 - val_loss: 4.1918\n",
      "Epoch 98/300\n",
      "200/200 [==============================] - 120s - loss: 6.6346 - val_loss: 4.1509\n",
      "Epoch 99/300\n",
      "200/200 [==============================] - 122s - loss: 6.1225 - val_loss: 4.1449\n",
      "Epoch 100/300\n",
      "200/200 [==============================] - 122s - loss: 6.6519 - val_loss: 4.0988\n",
      "Epoch 101/300\n",
      "200/200 [==============================] - 124s - loss: 5.9165 - val_loss: 4.1376\n",
      "Epoch 102/300\n",
      "200/200 [==============================] - 120s - loss: 6.4444 - val_loss: 4.1821\n",
      "Epoch 103/300\n",
      "200/200 [==============================] - 123s - loss: 6.5421 - val_loss: 4.1181\n",
      "Epoch 104/300\n",
      "200/200 [==============================] - 123s - loss: 6.1647 - val_loss: 4.1236\n",
      "Epoch 105/300\n",
      "200/200 [==============================] - 128s - loss: 5.9204 - val_loss: 4.0504\n",
      "Epoch 106/300\n",
      "200/200 [==============================] - 124s - loss: 6.2142 - val_loss: 4.0984\n",
      "Epoch 107/300\n",
      "200/200 [==============================] - 119s - loss: 6.1561 - val_loss: 4.0736\n",
      "Epoch 108/300\n",
      "200/200 [==============================] - 124s - loss: 6.2299 - val_loss: 4.0303\n",
      "Epoch 109/300\n",
      "200/200 [==============================] - 125s - loss: 5.8111 - val_loss: 4.0549\n",
      "Epoch 110/300\n",
      "200/200 [==============================] - 123s - loss: 6.4944 - val_loss: 4.0677\n",
      "Epoch 111/300\n",
      "200/200 [==============================] - 122s - loss: 6.2914 - val_loss: 4.0388\n",
      "Epoch 112/300\n",
      "200/200 [==============================] - 124s - loss: 5.9910 - val_loss: 4.0308\n",
      "Epoch 113/300\n",
      "200/200 [==============================] - 130s - loss: 6.2273 - val_loss: 4.0598\n",
      "Epoch 114/300\n",
      "200/200 [==============================] - 124s - loss: 6.2673 - val_loss: 4.0298\n",
      "Epoch 115/300\n",
      "200/200 [==============================] - 124s - loss: 6.0029 - val_loss: 4.0099\n",
      "Epoch 116/300\n",
      "200/200 [==============================] - 118s - loss: 6.0370 - val_loss: 3.9935\n",
      "Epoch 117/300\n",
      "200/200 [==============================] - 124s - loss: 6.5315 - val_loss: 3.9819\n",
      "Epoch 118/300\n",
      "200/200 [==============================] - 129s - loss: 5.8219 - val_loss: 3.9410\n",
      "Epoch 119/300\n",
      "200/200 [==============================] - 122s - loss: 5.6882 - val_loss: 3.9262\n",
      "Epoch 120/300\n",
      "200/200 [==============================] - 123s - loss: 5.9168 - val_loss: 3.9228\n",
      "Epoch 121/300\n",
      "200/200 [==============================] - 129s - loss: 6.0641 - val_loss: 3.9463\n",
      "Epoch 122/300\n",
      "200/200 [==============================] - 121s - loss: 6.2878 - val_loss: 3.9313\n",
      "Epoch 123/300\n",
      "200/200 [==============================] - 121s - loss: 6.2208 - val_loss: 3.9396\n",
      "Epoch 124/300\n",
      "200/200 [==============================] - 118s - loss: 6.1042 - val_loss: 3.9860\n",
      "Epoch 125/300\n",
      "200/200 [==============================] - 129s - loss: 6.2749 - val_loss: 3.8765\n",
      "Epoch 126/300\n",
      "200/200 [==============================] - 119s - loss: 6.4626 - val_loss: 3.9510\n",
      "Epoch 127/300\n",
      "200/200 [==============================] - 119s - loss: 6.0442 - val_loss: 3.9267\n",
      "Epoch 128/300\n",
      "200/200 [==============================] - 123s - loss: 6.7393 - val_loss: 3.8877\n",
      "Epoch 129/300\n",
      "200/200 [==============================] - 125s - loss: 5.6473 - val_loss: 3.8968\n",
      "Epoch 130/300\n",
      "200/200 [==============================] - 130s - loss: 5.7124 - val_loss: 3.8438\n",
      "Epoch 131/300\n",
      "200/200 [==============================] - 124s - loss: 5.9001 - val_loss: 3.8507\n",
      "Epoch 132/300\n",
      "200/200 [==============================] - 125s - loss: 5.3952 - val_loss: 3.9003\n",
      "Epoch 133/300\n",
      "200/200 [==============================] - 123s - loss: 6.2582 - val_loss: 3.8871\n",
      "Epoch 134/300\n",
      "200/200 [==============================] - 118s - loss: 5.6764 - val_loss: 3.8314\n",
      "Epoch 135/300\n",
      "200/200 [==============================] - 127s - loss: 6.2632 - val_loss: 3.8888\n",
      "Epoch 136/300\n",
      "200/200 [==============================] - 132s - loss: 5.9176 - val_loss: 3.8128\n",
      "Epoch 137/300\n",
      "200/200 [==============================] - 117s - loss: 5.7022 - val_loss: 3.8277\n",
      "Epoch 138/300\n",
      "200/200 [==============================] - 124s - loss: 5.9167 - val_loss: 3.7957\n",
      "Epoch 139/300\n",
      "200/200 [==============================] - 130s - loss: 6.0302 - val_loss: 3.8364\n",
      "Epoch 140/300\n",
      "200/200 [==============================] - 126s - loss: 5.7727 - val_loss: 3.7968\n",
      "Epoch 141/300\n",
      "200/200 [==============================] - 116s - loss: 5.5655 - val_loss: 3.8082\n",
      "Epoch 142/300\n",
      "200/200 [==============================] - 130s - loss: 5.9478 - val_loss: 3.7825\n",
      "Epoch 143/300\n",
      "200/200 [==============================] - 121s - loss: 5.8903 - val_loss: 3.7744\n",
      "Epoch 144/300\n",
      "200/200 [==============================] - 128s - loss: 5.7447 - val_loss: 3.8284\n",
      "Epoch 145/300\n",
      "200/200 [==============================] - 128s - loss: 6.0389 - val_loss: 3.7780\n",
      "Epoch 146/300\n",
      "200/200 [==============================] - 119s - loss: 5.6421 - val_loss: 3.7656\n",
      "Epoch 147/300\n",
      "200/200 [==============================] - 120s - loss: 5.5057 - val_loss: 3.7601\n",
      "Epoch 148/300\n",
      "200/200 [==============================] - 125s - loss: 5.8690 - val_loss: 3.7667\n",
      "Epoch 149/300\n",
      "200/200 [==============================] - 123s - loss: 6.0302 - val_loss: 3.7677\n",
      "Epoch 150/300\n",
      "200/200 [==============================] - 126s - loss: 5.7090 - val_loss: 3.7449\n",
      "Epoch 151/300\n",
      "200/200 [==============================] - 124s - loss: 6.5462 - val_loss: 3.7655\n",
      "Epoch 152/300\n",
      "200/200 [==============================] - 122s - loss: 5.4025 - val_loss: 3.7443\n",
      "Epoch 153/300\n",
      "200/200 [==============================] - 128s - loss: 5.8660 - val_loss: 3.7565\n",
      "Epoch 154/300\n",
      "200/200 [==============================] - 121s - loss: 5.9779 - val_loss: 3.7338\n",
      "Epoch 155/300\n",
      "200/200 [==============================] - 125s - loss: 5.7643 - val_loss: 3.7290\n",
      "Epoch 156/300\n",
      "200/200 [==============================] - 130s - loss: 5.6562 - val_loss: 3.7435\n",
      "Epoch 157/300\n",
      "200/200 [==============================] - 128s - loss: 5.4949 - val_loss: 3.7413\n",
      "Epoch 158/300\n",
      "200/200 [==============================] - 124s - loss: 5.4899 - val_loss: 3.7166\n",
      "Epoch 159/300\n",
      "200/200 [==============================] - 125s - loss: 6.0021 - val_loss: 3.7061\n",
      "Epoch 160/300\n",
      "200/200 [==============================] - 122s - loss: 5.7389 - val_loss: 3.7079\n",
      "Epoch 161/300\n",
      "200/200 [==============================] - 128s - loss: 5.5444 - val_loss: 3.6861\n",
      "Epoch 162/300\n",
      "200/200 [==============================] - 125s - loss: 5.8532 - val_loss: 3.7060\n",
      "Epoch 163/300\n",
      "200/200 [==============================] - 127s - loss: 5.3903 - val_loss: 3.6934\n",
      "Epoch 164/300\n",
      "200/200 [==============================] - 133s - loss: 5.5522 - val_loss: 3.7106\n",
      "Epoch 165/300\n",
      "200/200 [==============================] - 123s - loss: 5.7335 - val_loss: 3.6808\n",
      "Epoch 166/300\n",
      "200/200 [==============================] - 122s - loss: 5.5484 - val_loss: 3.6875\n",
      "Epoch 167/300\n",
      "200/200 [==============================] - 128s - loss: 5.5193 - val_loss: 3.6084\n",
      "Epoch 168/300\n",
      "200/200 [==============================] - 123s - loss: 5.3508 - val_loss: 3.7097\n",
      "Epoch 169/300\n",
      "200/200 [==============================] - 125s - loss: 5.7541 - val_loss: 3.6506\n",
      "Epoch 170/300\n",
      "200/200 [==============================] - 125s - loss: 5.8931 - val_loss: 3.6646\n",
      "Epoch 171/300\n",
      "200/200 [==============================] - 126s - loss: 5.2795 - val_loss: 3.6526\n",
      "Epoch 172/300\n",
      "200/200 [==============================] - 122s - loss: 6.0137 - val_loss: 3.6352\n",
      "Epoch 173/300\n",
      "200/200 [==============================] - 129s - loss: 5.4816 - val_loss: 3.6181\n",
      "Epoch 174/300\n",
      "200/200 [==============================] - 124s - loss: 5.4976 - val_loss: 3.6003\n",
      "Epoch 175/300\n",
      "200/200 [==============================] - 130s - loss: 5.6954 - val_loss: 3.6009\n",
      "Epoch 176/300\n",
      "200/200 [==============================] - 132s - loss: 6.1252 - val_loss: 3.5970\n",
      "Epoch 177/300\n",
      "200/200 [==============================] - 128s - loss: 5.2717 - val_loss: 3.5985\n",
      "Epoch 178/300\n",
      "200/200 [==============================] - 125s - loss: 5.7726 - val_loss: 3.5950\n",
      "Epoch 179/300\n",
      "200/200 [==============================] - 129s - loss: 5.5356 - val_loss: 3.5929\n",
      "Epoch 180/300\n",
      "200/200 [==============================] - 130s - loss: 5.6567 - val_loss: 3.5928\n",
      "Epoch 181/300\n",
      "200/200 [==============================] - 129s - loss: 5.4049 - val_loss: 3.5886\n",
      "Epoch 182/300\n",
      "200/200 [==============================] - 118s - loss: 5.7059 - val_loss: 3.5964\n",
      "Epoch 183/300\n",
      "200/200 [==============================] - 125s - loss: 6.0644 - val_loss: 3.5881\n",
      "Epoch 184/300\n",
      "200/200 [==============================] - 128s - loss: 5.3589 - val_loss: 3.5916\n",
      "Epoch 185/300\n",
      "200/200 [==============================] - 129s - loss: 5.4992 - val_loss: 3.5796\n",
      "Epoch 186/300\n",
      "200/200 [==============================] - 129s - loss: 5.3308 - val_loss: 3.5863\n",
      "Epoch 187/300\n",
      "200/200 [==============================] - 121s - loss: 5.4550 - val_loss: 3.5906\n",
      "Epoch 188/300\n",
      "200/200 [==============================] - 129s - loss: 5.5889 - val_loss: 3.5869\n",
      "Epoch 189/300\n",
      "200/200 [==============================] - 128s - loss: 5.4211 - val_loss: 3.5844\n",
      "Epoch 190/300\n",
      "200/200 [==============================] - 126s - loss: 5.2809 - val_loss: 3.5783\n",
      "Epoch 191/300\n",
      "200/200 [==============================] - 128s - loss: 5.1596 - val_loss: 3.5813\n",
      "Epoch 192/300\n",
      "200/200 [==============================] - 125s - loss: 5.3458 - val_loss: 3.5842\n",
      "Epoch 193/300\n",
      "200/200 [==============================] - 124s - loss: 5.4229 - val_loss: 3.5816\n",
      "Epoch 194/300\n",
      "200/200 [==============================] - 131s - loss: 5.7862 - val_loss: 3.5864\n",
      "Epoch 195/300\n",
      "200/200 [==============================] - 130s - loss: 5.4157 - val_loss: 3.5810\n",
      "Epoch 196/300\n",
      "200/200 [==============================] - 136s - loss: 5.5751 - val_loss: 3.5821\n",
      "Epoch 197/300\n",
      "200/200 [==============================] - 139s - loss: 5.2219 - val_loss: 3.5777\n",
      "Epoch 198/300\n",
      "200/200 [==============================] - 136s - loss: 5.6392 - val_loss: 3.5738\n",
      "Epoch 199/300\n",
      " 13/200 [>.............................] - ETA: 87s - loss: 5.2425"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-26-ffded0883e05>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     45\u001b[0m h = model.fit_generator(read_generator(csv, './public_data/00_input/train/images', 30), steps_per_epoch=len(csv) // 30, \n\u001b[0;32m     46\u001b[0m                         \u001b[0mepochs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m300\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcallbacks\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mcheckpoint_callback\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mearly_callback\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlr_callback\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 47\u001b[1;33m                         \u001b[0mvalidation_data\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtest\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     48\u001b[0m                        )\n\u001b[0;32m     49\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\python.Anaconda\\envs\\tensorflow\\lib\\site-packages\\keras\\legacy\\interfaces.py\u001b[0m in \u001b[0;36mwrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     85\u001b[0m                 warnings.warn('Update your `' + object_name +\n\u001b[0;32m     86\u001b[0m                               '` call to the Keras 2 API: ' + signature, stacklevel=2)\n\u001b[1;32m---> 87\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     88\u001b[0m         \u001b[0mwrapper\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_original_function\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     89\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\python.Anaconda\\envs\\tensorflow\\lib\\site-packages\\keras\\models.py\u001b[0m in \u001b[0;36mfit_generator\u001b[1;34m(self, generator, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, class_weight, max_queue_size, workers, use_multiprocessing, initial_epoch)\u001b[0m\n\u001b[0;32m   1119\u001b[0m                                         \u001b[0mworkers\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mworkers\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1120\u001b[0m                                         \u001b[0muse_multiprocessing\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0muse_multiprocessing\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1121\u001b[1;33m                                         initial_epoch=initial_epoch)\n\u001b[0m\u001b[0;32m   1122\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1123\u001b[0m     \u001b[1;33m@\u001b[0m\u001b[0minterfaces\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlegacy_generator_methods_support\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\python.Anaconda\\envs\\tensorflow\\lib\\site-packages\\keras\\legacy\\interfaces.py\u001b[0m in \u001b[0;36mwrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     85\u001b[0m                 warnings.warn('Update your `' + object_name +\n\u001b[0;32m     86\u001b[0m                               '` call to the Keras 2 API: ' + signature, stacklevel=2)\n\u001b[1;32m---> 87\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     88\u001b[0m         \u001b[0mwrapper\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_original_function\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     89\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\python.Anaconda\\envs\\tensorflow\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit_generator\u001b[1;34m(self, generator, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch)\u001b[0m\n\u001b[0;32m   2009\u001b[0m                 \u001b[0mbatch_index\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2010\u001b[0m                 \u001b[1;32mwhile\u001b[0m \u001b[0msteps_done\u001b[0m \u001b[1;33m<\u001b[0m \u001b[0msteps_per_epoch\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2011\u001b[1;33m                     \u001b[0mgenerator_output\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnext\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0moutput_generator\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2012\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2013\u001b[0m                     \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mgenerator_output\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'__len__'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\python.Anaconda\\envs\\tensorflow\\lib\\site-packages\\keras\\utils\\data_utils.py\u001b[0m in \u001b[0;36mget\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    642\u001b[0m                     \u001b[1;32myield\u001b[0m \u001b[0minputs\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    643\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 644\u001b[1;33m                 \u001b[0mtime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msleep\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwait_time\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "nb_epoch = 1\n",
    "validation_split = 0.2\n",
    "lr = 0.01\n",
    "momentum = 0.9\n",
    "nesterov = True\n",
    "loss_method = 'mean_squared_error'\n",
    "model = Sequential()\n",
    "\n",
    "model.add(Conv2D(64, (3, 3), input_shape=(100, 100, 1), activation='relu', data_format='channels_last'))\n",
    "# model.add(BatchNormalization())\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Dropout(0.1))\n",
    "\n",
    "model.add(Conv2D(64, (3, 3), activation='relu'))\n",
    "# model.add(BatchNormalization())\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Dropout(0.2))\n",
    "\n",
    "model.add(Conv2D(64, (3, 3), activation='relu'))\n",
    "# model.add(BatchNormalization())\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Dropout(0.2))\n",
    "\n",
    "model.add(Conv2D(128, (3, 3), activation='relu'))\n",
    "model.add(Conv2D(128, (3, 3), activation='relu'))\n",
    "# model.add(BatchNormalization())\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Dropout(0.3))\n",
    "\n",
    "model.add(Flatten())\n",
    "model.add(Dense(1000, activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(500, activation='relu'))\n",
    "model.add(Dense(28))\n",
    "\n",
    "sgd = SGD(lr=lr, momentum=momentum, nesterov=nesterov)\n",
    "adadelta = Adadelta(lr=1)\n",
    "model.compile(loss=loss_method, optimizer=Adam(lr=))\n",
    "checkpoint_callback = ModelCheckpoint(filepath = 'checkpoint.hdf5', monitor='val_loss', save_best_only=True, mode='auto')\n",
    "early_callback = EarlyStopping(patience=15)\n",
    "lr_callback = ReduceLROnPlateau(patience=5,)\n",
    "\n",
    "# h = model.fit(train, y_train, batch_size=16, shuffle=True, epochs=70, validation_split=0.2, \n",
    "#               callbacks=[checkpoint_callback, early_callback, lr_callback])\n",
    "h = model.fit_generator(read_generator(csv, './public_data/00_input/train/images', 30), steps_per_epoch=len(csv) // 30, \n",
    "                        epochs=300, callbacks=[checkpoint_callback, early_callback, lr_callback],\n",
    "                        validation_data=(test, y_test)\n",
    "                       )\n",
    "\n",
    "save_model(model, 'facepoints_model.hdf5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/300\n",
      "200/200 [==============================] - 108s - loss: 16.6805 - val_loss: 13.7060\n",
      "Epoch 2/300\n",
      "200/200 [==============================] - 114s - loss: 16.8910 - val_loss: 13.7323\n",
      "Epoch 3/300\n",
      "200/200 [==============================] - 120s - loss: 16.5929 - val_loss: 13.8437\n",
      "Epoch 4/300\n",
      "200/200 [==============================] - 111s - loss: 16.5394 - val_loss: 13.8737\n",
      "Epoch 5/300\n",
      "200/200 [==============================] - 114s - loss: 16.5655 - val_loss: 13.9188\n",
      "Epoch 6/300\n",
      "200/200 [==============================] - 113s - loss: 17.0926 - val_loss: 13.9278\n",
      "Epoch 7/300\n",
      "200/200 [==============================] - 124s - loss: 17.1506 - val_loss: 13.8686\n",
      "Epoch 8/300\n",
      "200/200 [==============================] - 114s - loss: 17.0550 - val_loss: 13.8684\n",
      "Epoch 9/300\n",
      "200/200 [==============================] - 114s - loss: 17.1388 - val_loss: 13.8738\n",
      "Epoch 10/300\n",
      "200/200 [==============================] - 119s - loss: 17.1696 - val_loss: 13.8759\n",
      "Epoch 11/300\n",
      "200/200 [==============================] - 118s - loss: 16.2935 - val_loss: 13.8773\n",
      "Epoch 12/300\n",
      "200/200 [==============================] - 116s - loss: 16.4017 - val_loss: 13.8764\n",
      "Epoch 13/300\n",
      "200/200 [==============================] - 117s - loss: 16.9584 - val_loss: 13.8764\n",
      "Epoch 14/300\n",
      "200/200 [==============================] - 115s - loss: 16.8235 - val_loss: 13.8764\n",
      "Epoch 15/300\n",
      "200/200 [==============================] - 125s - loss: 16.8356 - val_loss: 13.8764\n",
      "Epoch 16/300\n",
      "199/200 [============================>.] - ETA: 0s - loss: 17.5548"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-23-220852a38167>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      4\u001b[0m h = model.fit_generator(read_generator(csv, './public_data/00_input/train/images', 30), steps_per_epoch=len(csv) // 30, \n\u001b[0;32m      5\u001b[0m                         \u001b[0mepochs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m300\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcallbacks\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mcheckpoint_callback\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlr_callback\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 6\u001b[1;33m                         \u001b[0mvalidation_data\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtest\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      7\u001b[0m                        )\n\u001b[0;32m      8\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\python.Anaconda\\envs\\tensorflow\\lib\\site-packages\\keras\\legacy\\interfaces.py\u001b[0m in \u001b[0;36mwrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     85\u001b[0m                 warnings.warn('Update your `' + object_name +\n\u001b[0;32m     86\u001b[0m                               '` call to the Keras 2 API: ' + signature, stacklevel=2)\n\u001b[1;32m---> 87\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     88\u001b[0m         \u001b[0mwrapper\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_original_function\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     89\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\python.Anaconda\\envs\\tensorflow\\lib\\site-packages\\keras\\models.py\u001b[0m in \u001b[0;36mfit_generator\u001b[1;34m(self, generator, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, class_weight, max_queue_size, workers, use_multiprocessing, initial_epoch)\u001b[0m\n\u001b[0;32m   1119\u001b[0m                                         \u001b[0mworkers\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mworkers\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1120\u001b[0m                                         \u001b[0muse_multiprocessing\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0muse_multiprocessing\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1121\u001b[1;33m                                         initial_epoch=initial_epoch)\n\u001b[0m\u001b[0;32m   1122\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1123\u001b[0m     \u001b[1;33m@\u001b[0m\u001b[0minterfaces\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlegacy_generator_methods_support\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\python.Anaconda\\envs\\tensorflow\\lib\\site-packages\\keras\\legacy\\interfaces.py\u001b[0m in \u001b[0;36mwrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     85\u001b[0m                 warnings.warn('Update your `' + object_name +\n\u001b[0;32m     86\u001b[0m                               '` call to the Keras 2 API: ' + signature, stacklevel=2)\n\u001b[1;32m---> 87\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     88\u001b[0m         \u001b[0mwrapper\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_original_function\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     89\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\python.Anaconda\\envs\\tensorflow\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit_generator\u001b[1;34m(self, generator, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch)\u001b[0m\n\u001b[0;32m   2070\u001b[0m                                 \u001b[0mbatch_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2071\u001b[0m                                 \u001b[0msample_weight\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mval_sample_weights\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2072\u001b[1;33m                                 verbose=0)\n\u001b[0m\u001b[0;32m   2073\u001b[0m                         \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mval_outs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2074\u001b[0m                             \u001b[0mval_outs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mval_outs\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\python.Anaconda\\envs\\tensorflow\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mevaluate\u001b[1;34m(self, x, y, batch_size, verbose, sample_weight, steps)\u001b[0m\n\u001b[0;32m   1655\u001b[0m                                \u001b[0mbatch_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1656\u001b[0m                                \u001b[0mverbose\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mverbose\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1657\u001b[1;33m                                steps=steps)\n\u001b[0m\u001b[0;32m   1658\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1659\u001b[0m     def predict(self, x,\n",
      "\u001b[1;32mD:\\python.Anaconda\\envs\\tensorflow\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36m_test_loop\u001b[1;34m(self, f, ins, batch_size, verbose, steps)\u001b[0m\n\u001b[0;32m   1337\u001b[0m                     \u001b[0mins_batch\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_slice_arrays\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mins\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_ids\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1338\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1339\u001b[1;33m                 \u001b[0mbatch_outs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1340\u001b[0m                 \u001b[1;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbatch_outs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1341\u001b[0m                     \u001b[1;32mif\u001b[0m \u001b[0mbatch_index\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\python.Anaconda\\envs\\tensorflow\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, inputs)\u001b[0m\n\u001b[0;32m   2271\u001b[0m         updated = session.run(self.outputs + [self.updates_op],\n\u001b[0;32m   2272\u001b[0m                               \u001b[0mfeed_dict\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mfeed_dict\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2273\u001b[1;33m                               **self.session_kwargs)\n\u001b[0m\u001b[0;32m   2274\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mupdated\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2275\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\python.Anaconda\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36mrun\u001b[1;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m    776\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    777\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[1;32m--> 778\u001b[1;33m                          run_metadata_ptr)\n\u001b[0m\u001b[0;32m    779\u001b[0m       \u001b[1;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    780\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\python.Anaconda\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_run\u001b[1;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m    980\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    981\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[1;32m--> 982\u001b[1;33m                              feed_dict_string, options, run_metadata)\n\u001b[0m\u001b[0;32m    983\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    984\u001b[0m       \u001b[0mresults\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\python.Anaconda\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_do_run\u001b[1;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m   1030\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1031\u001b[0m       return self._do_call(_run_fn, self._session, feed_dict, fetch_list,\n\u001b[1;32m-> 1032\u001b[1;33m                            target_list, options, run_metadata)\n\u001b[0m\u001b[0;32m   1033\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1034\u001b[0m       return self._do_call(_prun_fn, self._session, handle, feed_dict,\n",
      "\u001b[1;32mD:\\python.Anaconda\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_do_call\u001b[1;34m(self, fn, *args)\u001b[0m\n\u001b[0;32m   1037\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_do_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1038\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1039\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1040\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1041\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcompat\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\python.Anaconda\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[1;34m(session, feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[0;32m   1019\u001b[0m         return tf_session.TF_Run(session, options,\n\u001b[0;32m   1020\u001b[0m                                  \u001b[0mfeed_dict\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1021\u001b[1;33m                                  status, run_metadata)\n\u001b[0m\u001b[0;32m   1022\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1023\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_prun_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msession\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# 17.2 vs 13.9\n",
    "\n",
    "model.compile(loss=loss_method, optimizer=Adam(lr=0.0001, decay=1))\n",
    "h = model.fit_generator(read_generator(csv, './public_data/00_input/train/images', 30), steps_per_epoch=len(csv) // 30, \n",
    "                        epochs=300, callbacks=[checkpoint_callback, lr_callback],\n",
    "                        validation_data=(test, y_test)\n",
    "                       )\n",
    "\n",
    "save_model(model, 'facepoints_model.hdf5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false,
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [
    {
     "ename": "ResourceExhaustedError",
     "evalue": "OOM when allocating tensor with shape[12800,1000]\n\t [[Node: dense_4_7/random_uniform/RandomUniform = RandomUniform[T=DT_INT32, dtype=DT_FLOAT, seed=87654321, seed2=269283, _device=\"/job:localhost/replica:0/task:0/gpu:0\"](dense_4_7/random_uniform/shape)]]\n\nCaused by op 'dense_4_7/random_uniform/RandomUniform', defined at:\n  File \"D:\\python.Anaconda\\envs\\tensorflow\\lib\\runpy.py\", line 193, in _run_module_as_main\n    \"__main__\", mod_spec)\n  File \"D:\\python.Anaconda\\envs\\tensorflow\\lib\\runpy.py\", line 85, in _run_code\n    exec(code, run_globals)\n  File \"D:\\python.Anaconda\\envs\\tensorflow\\lib\\site-packages\\ipykernel_launcher.py\", line 16, in <module>\n    app.launch_new_instance()\n  File \"D:\\python.Anaconda\\envs\\tensorflow\\lib\\site-packages\\traitlets\\config\\application.py\", line 658, in launch_instance\n    app.start()\n  File \"D:\\python.Anaconda\\envs\\tensorflow\\lib\\site-packages\\ipykernel\\kernelapp.py\", line 477, in start\n    ioloop.IOLoop.instance().start()\n  File \"D:\\python.Anaconda\\envs\\tensorflow\\lib\\site-packages\\zmq\\eventloop\\ioloop.py\", line 177, in start\n    super(ZMQIOLoop, self).start()\n  File \"D:\\python.Anaconda\\envs\\tensorflow\\lib\\site-packages\\tornado\\ioloop.py\", line 888, in start\n    handler_func(fd_obj, events)\n  File \"D:\\python.Anaconda\\envs\\tensorflow\\lib\\site-packages\\tornado\\stack_context.py\", line 277, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"D:\\python.Anaconda\\envs\\tensorflow\\lib\\site-packages\\zmq\\eventloop\\zmqstream.py\", line 440, in _handle_events\n    self._handle_recv()\n  File \"D:\\python.Anaconda\\envs\\tensorflow\\lib\\site-packages\\zmq\\eventloop\\zmqstream.py\", line 472, in _handle_recv\n    self._run_callback(callback, msg)\n  File \"D:\\python.Anaconda\\envs\\tensorflow\\lib\\site-packages\\zmq\\eventloop\\zmqstream.py\", line 414, in _run_callback\n    callback(*args, **kwargs)\n  File \"D:\\python.Anaconda\\envs\\tensorflow\\lib\\site-packages\\tornado\\stack_context.py\", line 277, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"D:\\python.Anaconda\\envs\\tensorflow\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 283, in dispatcher\n    return self.dispatch_shell(stream, msg)\n  File \"D:\\python.Anaconda\\envs\\tensorflow\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 235, in dispatch_shell\n    handler(stream, idents, msg)\n  File \"D:\\python.Anaconda\\envs\\tensorflow\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 399, in execute_request\n    user_expressions, allow_stdin)\n  File \"D:\\python.Anaconda\\envs\\tensorflow\\lib\\site-packages\\ipykernel\\ipkernel.py\", line 196, in do_execute\n    res = shell.run_cell(code, store_history=store_history, silent=silent)\n  File \"D:\\python.Anaconda\\envs\\tensorflow\\lib\\site-packages\\ipykernel\\zmqshell.py\", line 533, in run_cell\n    return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n  File \"D:\\python.Anaconda\\envs\\tensorflow\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2698, in run_cell\n    interactivity=interactivity, compiler=compiler, result=result)\n  File \"D:\\python.Anaconda\\envs\\tensorflow\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2802, in run_ast_nodes\n    if self.run_code(code, result):\n  File \"D:\\python.Anaconda\\envs\\tensorflow\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2862, in run_code\n    exec(code_obj, self.user_global_ns, self.user_ns)\n  File \"<ipython-input-26-d8922d4db2c7>\", line 3, in <module>\n    ms = load_model('checkpoint.hdf5')\n  File \"D:\\python.Anaconda\\envs\\tensorflow\\lib\\site-packages\\keras\\models.py\", line 239, in load_model\n    model = model_from_config(model_config, custom_objects=custom_objects)\n  File \"D:\\python.Anaconda\\envs\\tensorflow\\lib\\site-packages\\keras\\models.py\", line 313, in model_from_config\n    return layer_module.deserialize(config, custom_objects=custom_objects)\n  File \"D:\\python.Anaconda\\envs\\tensorflow\\lib\\site-packages\\keras\\layers\\__init__.py\", line 54, in deserialize\n    printable_module_name='layer')\n  File \"D:\\python.Anaconda\\envs\\tensorflow\\lib\\site-packages\\keras\\utils\\generic_utils.py\", line 139, in deserialize_keras_object\n    list(custom_objects.items())))\n  File \"D:\\python.Anaconda\\envs\\tensorflow\\lib\\site-packages\\keras\\models.py\", line 1214, in from_config\n    model.add(layer)\n  File \"D:\\python.Anaconda\\envs\\tensorflow\\lib\\site-packages\\keras\\models.py\", line 475, in add\n    output_tensor = layer(self.outputs[0])\n  File \"D:\\python.Anaconda\\envs\\tensorflow\\lib\\site-packages\\keras\\engine\\topology.py\", line 575, in __call__\n    self.build(input_shapes[0])\n  File \"D:\\python.Anaconda\\envs\\tensorflow\\lib\\site-packages\\keras\\layers\\core.py\", line 828, in build\n    constraint=self.kernel_constraint)\n  File \"D:\\python.Anaconda\\envs\\tensorflow\\lib\\site-packages\\keras\\legacy\\interfaces.py\", line 87, in wrapper\n    return func(*args, **kwargs)\n  File \"D:\\python.Anaconda\\envs\\tensorflow\\lib\\site-packages\\keras\\engine\\topology.py\", line 396, in add_weight\n    weight = K.variable(initializer(shape),\n  File \"D:\\python.Anaconda\\envs\\tensorflow\\lib\\site-packages\\keras\\initializers.py\", line 212, in __call__\n    dtype=dtype, seed=self.seed)\n  File \"D:\\python.Anaconda\\envs\\tensorflow\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py\", line 3544, in random_uniform\n    dtype=dtype, seed=seed)\n  File \"D:\\python.Anaconda\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\ops\\random_ops.py\", line 236, in random_uniform\n    shape, dtype, seed=seed1, seed2=seed2)\n  File \"D:\\python.Anaconda\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\ops\\gen_random_ops.py\", line 263, in _random_uniform\n    seed=seed, seed2=seed2, name=name)\n  File \"D:\\python.Anaconda\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\framework\\op_def_library.py\", line 768, in apply_op\n    op_def=op_def)\n  File \"D:\\python.Anaconda\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\", line 2336, in create_op\n    original_op=self._default_original_op, op_def=op_def)\n  File \"D:\\python.Anaconda\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\", line 1228, in __init__\n    self._traceback = _extract_stack()\n\nResourceExhaustedError (see above for traceback): OOM when allocating tensor with shape[12800,1000]\n\t [[Node: dense_4_7/random_uniform/RandomUniform = RandomUniform[T=DT_INT32, dtype=DT_FLOAT, seed=87654321, seed2=269283, _device=\"/job:localhost/replica:0/task:0/gpu:0\"](dense_4_7/random_uniform/shape)]]\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mResourceExhaustedError\u001b[0m                    Traceback (most recent call last)",
      "\u001b[1;32mD:\\python.Anaconda\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_do_call\u001b[1;34m(self, fn, *args)\u001b[0m\n\u001b[0;32m   1038\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1039\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1040\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\python.Anaconda\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[1;34m(session, feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[0;32m   1020\u001b[0m                                  \u001b[0mfeed_dict\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1021\u001b[1;33m                                  status, run_metadata)\n\u001b[0m\u001b[0;32m   1022\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\python.Anaconda\\envs\\tensorflow\\lib\\contextlib.py\u001b[0m in \u001b[0;36m__exit__\u001b[1;34m(self, type, value, traceback)\u001b[0m\n\u001b[0;32m     65\u001b[0m             \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 66\u001b[1;33m                 \u001b[0mnext\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgen\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     67\u001b[0m             \u001b[1;32mexcept\u001b[0m \u001b[0mStopIteration\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\python.Anaconda\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\framework\\errors_impl.py\u001b[0m in \u001b[0;36mraise_exception_on_not_ok_status\u001b[1;34m()\u001b[0m\n\u001b[0;32m    465\u001b[0m           \u001b[0mcompat\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpywrap_tensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTF_Message\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstatus\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 466\u001b[1;33m           pywrap_tensorflow.TF_GetCode(status))\n\u001b[0m\u001b[0;32m    467\u001b[0m   \u001b[1;32mfinally\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mResourceExhaustedError\u001b[0m: OOM when allocating tensor with shape[12800,1000]\n\t [[Node: dense_4_7/random_uniform/RandomUniform = RandomUniform[T=DT_INT32, dtype=DT_FLOAT, seed=87654321, seed2=269283, _device=\"/job:localhost/replica:0/task:0/gpu:0\"](dense_4_7/random_uniform/shape)]]",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mResourceExhaustedError\u001b[0m                    Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-26-d8922d4db2c7>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mpreprocessing\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mprepare_image_test\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mmatplotlib\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpyplot\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mplt\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[0mms\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mload_model\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'checkpoint.hdf5'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mgt_csv\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mread_csv\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'./public_data/00_input/train/gt.csv'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\python.Anaconda\\envs\\tensorflow\\lib\\site-packages\\keras\\models.py\u001b[0m in \u001b[0;36mload_model\u001b[1;34m(filepath, custom_objects, compile)\u001b[0m\n\u001b[0;32m    240\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    241\u001b[0m         \u001b[1;31m# set weights\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 242\u001b[1;33m         \u001b[0mtopology\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mload_weights_from_hdf5_group\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mf\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'model_weights'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlayers\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    243\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    244\u001b[0m         \u001b[1;31m# Early return if compilation is not required.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\python.Anaconda\\envs\\tensorflow\\lib\\site-packages\\keras\\engine\\topology.py\u001b[0m in \u001b[0;36mload_weights_from_hdf5_group\u001b[1;34m(f, layers)\u001b[0m\n\u001b[0;32m   3093\u001b[0m                              ' elements.')\n\u001b[0;32m   3094\u001b[0m         \u001b[0mweight_value_tuples\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[0mzip\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msymbolic_weights\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mweight_values\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3095\u001b[1;33m     \u001b[0mK\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbatch_set_value\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mweight_value_tuples\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   3096\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3097\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\python.Anaconda\\envs\\tensorflow\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py\u001b[0m in \u001b[0;36mbatch_set_value\u001b[1;34m(tuples)\u001b[0m\n\u001b[0;32m   2191\u001b[0m             \u001b[0massign_ops\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0massign_op\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2192\u001b[0m             \u001b[0mfeed_dict\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0massign_placeholder\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mvalue\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2193\u001b[1;33m         \u001b[0mget_session\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0massign_ops\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mfeed_dict\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2194\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2195\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\python.Anaconda\\envs\\tensorflow\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py\u001b[0m in \u001b[0;36mget_session\u001b[1;34m()\u001b[0m\n\u001b[0;32m    165\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0m_MANUAL_VAR_INIT\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    166\u001b[0m         \u001b[1;32mwith\u001b[0m \u001b[0msession\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgraph\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mas_default\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 167\u001b[1;33m             \u001b[0m_initialize_variables\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    168\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0msession\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    169\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\python.Anaconda\\envs\\tensorflow\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py\u001b[0m in \u001b[0;36m_initialize_variables\u001b[1;34m()\u001b[0m\n\u001b[0;32m    339\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0muninitialized_variables\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    340\u001b[0m         \u001b[0msess\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mget_session\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 341\u001b[1;33m         \u001b[0msess\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvariables_initializer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0muninitialized_variables\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    342\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    343\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\python.Anaconda\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36mrun\u001b[1;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m    776\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    777\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[1;32m--> 778\u001b[1;33m                          run_metadata_ptr)\n\u001b[0m\u001b[0;32m    779\u001b[0m       \u001b[1;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    780\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\python.Anaconda\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_run\u001b[1;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m    980\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    981\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[1;32m--> 982\u001b[1;33m                              feed_dict_string, options, run_metadata)\n\u001b[0m\u001b[0;32m    983\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    984\u001b[0m       \u001b[0mresults\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\python.Anaconda\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_do_run\u001b[1;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m   1030\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1031\u001b[0m       return self._do_call(_run_fn, self._session, feed_dict, fetch_list,\n\u001b[1;32m-> 1032\u001b[1;33m                            target_list, options, run_metadata)\n\u001b[0m\u001b[0;32m   1033\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1034\u001b[0m       return self._do_call(_prun_fn, self._session, handle, feed_dict,\n",
      "\u001b[1;32mD:\\python.Anaconda\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_do_call\u001b[1;34m(self, fn, *args)\u001b[0m\n\u001b[0;32m   1050\u001b[0m         \u001b[1;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1051\u001b[0m           \u001b[1;32mpass\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1052\u001b[1;33m       \u001b[1;32mraise\u001b[0m \u001b[0mtype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnode_def\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mop\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmessage\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1053\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1054\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_extend_graph\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mResourceExhaustedError\u001b[0m: OOM when allocating tensor with shape[12800,1000]\n\t [[Node: dense_4_7/random_uniform/RandomUniform = RandomUniform[T=DT_INT32, dtype=DT_FLOAT, seed=87654321, seed2=269283, _device=\"/job:localhost/replica:0/task:0/gpu:0\"](dense_4_7/random_uniform/shape)]]\n\nCaused by op 'dense_4_7/random_uniform/RandomUniform', defined at:\n  File \"D:\\python.Anaconda\\envs\\tensorflow\\lib\\runpy.py\", line 193, in _run_module_as_main\n    \"__main__\", mod_spec)\n  File \"D:\\python.Anaconda\\envs\\tensorflow\\lib\\runpy.py\", line 85, in _run_code\n    exec(code, run_globals)\n  File \"D:\\python.Anaconda\\envs\\tensorflow\\lib\\site-packages\\ipykernel_launcher.py\", line 16, in <module>\n    app.launch_new_instance()\n  File \"D:\\python.Anaconda\\envs\\tensorflow\\lib\\site-packages\\traitlets\\config\\application.py\", line 658, in launch_instance\n    app.start()\n  File \"D:\\python.Anaconda\\envs\\tensorflow\\lib\\site-packages\\ipykernel\\kernelapp.py\", line 477, in start\n    ioloop.IOLoop.instance().start()\n  File \"D:\\python.Anaconda\\envs\\tensorflow\\lib\\site-packages\\zmq\\eventloop\\ioloop.py\", line 177, in start\n    super(ZMQIOLoop, self).start()\n  File \"D:\\python.Anaconda\\envs\\tensorflow\\lib\\site-packages\\tornado\\ioloop.py\", line 888, in start\n    handler_func(fd_obj, events)\n  File \"D:\\python.Anaconda\\envs\\tensorflow\\lib\\site-packages\\tornado\\stack_context.py\", line 277, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"D:\\python.Anaconda\\envs\\tensorflow\\lib\\site-packages\\zmq\\eventloop\\zmqstream.py\", line 440, in _handle_events\n    self._handle_recv()\n  File \"D:\\python.Anaconda\\envs\\tensorflow\\lib\\site-packages\\zmq\\eventloop\\zmqstream.py\", line 472, in _handle_recv\n    self._run_callback(callback, msg)\n  File \"D:\\python.Anaconda\\envs\\tensorflow\\lib\\site-packages\\zmq\\eventloop\\zmqstream.py\", line 414, in _run_callback\n    callback(*args, **kwargs)\n  File \"D:\\python.Anaconda\\envs\\tensorflow\\lib\\site-packages\\tornado\\stack_context.py\", line 277, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"D:\\python.Anaconda\\envs\\tensorflow\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 283, in dispatcher\n    return self.dispatch_shell(stream, msg)\n  File \"D:\\python.Anaconda\\envs\\tensorflow\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 235, in dispatch_shell\n    handler(stream, idents, msg)\n  File \"D:\\python.Anaconda\\envs\\tensorflow\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 399, in execute_request\n    user_expressions, allow_stdin)\n  File \"D:\\python.Anaconda\\envs\\tensorflow\\lib\\site-packages\\ipykernel\\ipkernel.py\", line 196, in do_execute\n    res = shell.run_cell(code, store_history=store_history, silent=silent)\n  File \"D:\\python.Anaconda\\envs\\tensorflow\\lib\\site-packages\\ipykernel\\zmqshell.py\", line 533, in run_cell\n    return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n  File \"D:\\python.Anaconda\\envs\\tensorflow\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2698, in run_cell\n    interactivity=interactivity, compiler=compiler, result=result)\n  File \"D:\\python.Anaconda\\envs\\tensorflow\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2802, in run_ast_nodes\n    if self.run_code(code, result):\n  File \"D:\\python.Anaconda\\envs\\tensorflow\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2862, in run_code\n    exec(code_obj, self.user_global_ns, self.user_ns)\n  File \"<ipython-input-26-d8922d4db2c7>\", line 3, in <module>\n    ms = load_model('checkpoint.hdf5')\n  File \"D:\\python.Anaconda\\envs\\tensorflow\\lib\\site-packages\\keras\\models.py\", line 239, in load_model\n    model = model_from_config(model_config, custom_objects=custom_objects)\n  File \"D:\\python.Anaconda\\envs\\tensorflow\\lib\\site-packages\\keras\\models.py\", line 313, in model_from_config\n    return layer_module.deserialize(config, custom_objects=custom_objects)\n  File \"D:\\python.Anaconda\\envs\\tensorflow\\lib\\site-packages\\keras\\layers\\__init__.py\", line 54, in deserialize\n    printable_module_name='layer')\n  File \"D:\\python.Anaconda\\envs\\tensorflow\\lib\\site-packages\\keras\\utils\\generic_utils.py\", line 139, in deserialize_keras_object\n    list(custom_objects.items())))\n  File \"D:\\python.Anaconda\\envs\\tensorflow\\lib\\site-packages\\keras\\models.py\", line 1214, in from_config\n    model.add(layer)\n  File \"D:\\python.Anaconda\\envs\\tensorflow\\lib\\site-packages\\keras\\models.py\", line 475, in add\n    output_tensor = layer(self.outputs[0])\n  File \"D:\\python.Anaconda\\envs\\tensorflow\\lib\\site-packages\\keras\\engine\\topology.py\", line 575, in __call__\n    self.build(input_shapes[0])\n  File \"D:\\python.Anaconda\\envs\\tensorflow\\lib\\site-packages\\keras\\layers\\core.py\", line 828, in build\n    constraint=self.kernel_constraint)\n  File \"D:\\python.Anaconda\\envs\\tensorflow\\lib\\site-packages\\keras\\legacy\\interfaces.py\", line 87, in wrapper\n    return func(*args, **kwargs)\n  File \"D:\\python.Anaconda\\envs\\tensorflow\\lib\\site-packages\\keras\\engine\\topology.py\", line 396, in add_weight\n    weight = K.variable(initializer(shape),\n  File \"D:\\python.Anaconda\\envs\\tensorflow\\lib\\site-packages\\keras\\initializers.py\", line 212, in __call__\n    dtype=dtype, seed=self.seed)\n  File \"D:\\python.Anaconda\\envs\\tensorflow\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py\", line 3544, in random_uniform\n    dtype=dtype, seed=seed)\n  File \"D:\\python.Anaconda\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\ops\\random_ops.py\", line 236, in random_uniform\n    shape, dtype, seed=seed1, seed2=seed2)\n  File \"D:\\python.Anaconda\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\ops\\gen_random_ops.py\", line 263, in _random_uniform\n    seed=seed, seed2=seed2, name=name)\n  File \"D:\\python.Anaconda\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\framework\\op_def_library.py\", line 768, in apply_op\n    op_def=op_def)\n  File \"D:\\python.Anaconda\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\", line 2336, in create_op\n    original_op=self._default_original_op, op_def=op_def)\n  File \"D:\\python.Anaconda\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\", line 1228, in __init__\n    self._traceback = _extract_stack()\n\nResourceExhaustedError (see above for traceback): OOM when allocating tensor with shape[12800,1000]\n\t [[Node: dense_4_7/random_uniform/RandomUniform = RandomUniform[T=DT_INT32, dtype=DT_FLOAT, seed=87654321, seed2=269283, _device=\"/job:localhost/replica:0/task:0/gpu:0\"](dense_4_7/random_uniform/shape)]]\n"
     ]
    }
   ],
   "source": [
    "from preprocessing import prepare_image_test\n",
    "import matplotlib.pyplot as plt\n",
    "ms = load_model('checkpoint.hdf5')\n",
    "\n",
    "gt_csv = read_csv('./public_data/00_input/train/gt.csv')\n",
    "__img, __y_points = prepare_image_test('00000.jpg', gt_csv)\n",
    "    \n",
    "__pred_points = model.predict_on_batch(np.array([__img]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# ms = load_model('facepoints_model.hdf5')\n",
    "def pred_and_show(img_name, ms, gt_csv):\n",
    "    img, y_points = prepare_image_test(img_name, gt_csv)\n",
    "    img = rgb2grey(img)\n",
    "    pred_points = ms.predict(np.array([[img]]))\n",
    "    plt.imshow(img, cmap='Greys_r')\n",
    "    plt.scatter(y_points[0], y_points[1], c='orange', s=5);\n",
    "    plt.scatter(pred_points[0][::2], pred_points[0][1::2], c='blue', s=5);\n",
    "    plt.show()\n",
    "    \n",
    "pred_and_show('00002.jpg', model, gt_csv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYgAAAEKCAYAAAAIO8L1AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDIuMS4wLCBo\ndHRwOi8vbWF0cGxvdGxpYi5vcmcvpW3flQAAIABJREFUeJztnXd4HNXVh9+rXq1mSS6yLffeC6YY\njCGE5tDBtAAh8IU04EtCSCD5SEIaJCGBJBA6JLSEbmooNsbg3uXebUm2JKv3tvf74+5qZlcrabVa\neVfe8z6Pnr0zOzN7NLbmt+ece89RWmsEQRAEwZOIYBsgCIIghCYiEIIgCIJXRCAEQRAEr4hACIIg\nCF4RgRAEQRC8IgIhCIIgeEUEQhAEQfCKCIQgCILgFREIQRAEwStRwTagJ/Tv31/n5ub6dW5tbS2J\niYmBNShAiG3+Ibb5h9jmH33ZtnXr1h3TWmd2eSGtdZ/7ARYCj48aNUr7y5IlS/w+t7cR2/xDbPMP\nsc0/+rJtwFrtw7O2T4aYtNaLtda3pqSkBNsUQRCEE5Y+KRCCIAhC7yMCIQiCIHilTyepBUEQukNz\nczP5+fk0NDT0+FopKSls3749AFYFHpdtcXFx5OTkEB0d7dd1RCAEQQgb8vPzSU5OJjc3F6VUj65V\nXV1NcnJygCwLLNXV1SQlJVFaWkp+fj7Dhw/36zoSYhIEIWxoaGggIyOjx+LQF1BKkZGR0SNvSQTC\nG6V7obk+2FYIgtALhIM4uOjp7yoC4cmKv8EjM+CRWSISgiCENX1SIJRSC5VSj1dWVgb+4pteNq9V\n+XBoZeCvLwhCWFNRUcHf//73bp93/vnnU1FR0QsWdUyfFIheXShXedga15UG/vqCIIQ1HQlEa2tr\np+e99957pKam9pZZXpFZTHYaa6C+3NquPRY8WwRBOCG5++672bt3L9OmTSM6OpqkpCQGDhzIxo0b\n2bZtGxdffDGHDx+moaGB22+/nVtvvRWA3Nxc1q5dS01NDeeddx6nnXYaX375JYMHD+att94iPj4+\n4LaKQNixew8gHoQgnMDk3v1ur137wO8u6PC93/3ud+Tl5bFx40aWLl3KBRdcQF5eXttU1Keffpr0\n9HTq6+uZPXs2l112GRkZGW7X2L17Ny+99BJPPPEEV155Ja+99hrXXXddwH8PEQg7lfnu23XiQQiC\n0LvMmTPHbZ3Cww8/zBtvvAHA4cOH2b17dzuBGD58ONOmTQNg5syZHDhwoFdsE4GwU3HIfVtCTIIg\n9DL2stxLly7l448/ZsWKFSQkJDB//nyv6xhiY2PbxpGRkdTX986MSxEIOxJiEoSwobMwkC/4u5I6\nOTmZ6upqr+9VVlaSlpZGQkICO3bsYOXK4M6kFIGwU+EhEOJBCIIQYDIyMjj11FOZNGkS8fHxZGdn\nt7137rnn8thjjzFlyhTGjh3L3Llzg2ipCIQ77TwIEQhBEALPiy++6HV/bGws77//vtf3XHmG/v37\nk5eX17b/hz/8YcDtc9En10H0Gp5J6vpycHQ+N1kQBOFEpU8KRK+spG5thuoj7vu0A+qP78pFQRCE\nUKFPCkSvrKSuKjCC4ImEmQRBCFP6pED0Cp4JaheSqBYEIUwRgXDhmaB2IR6EIAhhigiEC88EtQvx\nIARBCFNEIFzYV1HH2nIbslhOEIQgkpSUBEBhYSGXX36512Pmz5/P2rVrA/7ZIhAu7CGmQVOtsQiE\nIAghwKBBg3j11VeP62eKQLiwJ6kHTbfGEmISBCGA/PjHP3brB3Hffffxi1/8grPOOosZM2YwefJk\n3nrrrXbnHThwgEmTJgFQX1/PokWLmDJlCldddZXUYupVHA73HMTAadZYktSCcGJyX8+myXdahem+\njtdoLVq0iDvuuINvf/vbAPz73//mgw8+4M4776Rfv34cO3aMuXPn8rWvfa3DntKPPvooCQkJbN68\nmc2bNzNjxowe/CYdIwIBRgRaG804LgXSrdK71EqISRCEwDF9+nSKi4spLCykpKSEtLQ0Bg4cyJ13\n3smyZcuIiIigoKCAoqIiBgwY4PUay5Yt4/vf/z4AU6ZMYcqUKb1iqwgEuIeXUoZCQn9rWzwIQRAC\nzOWXX86rr77K0aNHWbRoES+88AIlJSWsW7eO6OhocnNzvZb5ttORdxFIRCAAKm0zmFJyIMHWnKP2\nGGgNx+EfQxCE40gnYSBf8LfcN5gw0y233MKxY8f47LPP+Pe//01WVhbR0dEsWbKEgwcPdnr+6aef\nzgsvvMCZZ55JXl4emzdv9suOrpAkNbh7EKlDICYBohPMtqMZGquCY5cgCCckEydOpLq6msGDBzNw\n4ECuvfZa1q5dy6xZs3jhhRcYN25cp+ffdttt1NTUMGXKFB544AHmzJnTK3b2SQ9CKbUQWDhq1KjA\nXNA+xTVliHlN6G95FnWlJjchCIIQILZs2dI27t+/PytWrPB6XE1NDQC5ubltZb7j4+N5+eWXe93G\nPulBBLxYn30GU6pTIBLtYSZJVAuCEH70SYEIOJ5JapBEtSAIYY8IBLRPUgMk2gRCFssJwgmD1jrY\nJhw3evq7ikA0VEGDczZDZCwkZpqxfSaTeBCCcEIQFxdHaWlpWIiE1prS0lLi4uL8vkafTFIHFLcE\ndQ5EODXTc6qrIAh9npycHPLz8ykpKenxtRoaGnr08O1NXLbFxcWRk5Pj93VEILwlqME9xCQF+wTh\nhCA6Oprhw4d3faAPLF26lOnTp3d9YBAIlG0SYrKX+U6xCUSCCIQgCOGNCIS3NRAgSWpBEMIeEQjP\nVdQuJEktCEKYIwLhkwchISZBEMKPsBOI/PI63t5UyAvbGzlSWd9xkjq2H0REm3FzLTT3TkMOQRCE\nUCXsZjHd/doWlu8xIaOL9hVxYfVR5zsKkgdZByplwkw1zvdrj7kLiCAIwglO2HkQ04akto33790F\nOBfMJA+EqBj3g2WqqyAIYUxYC0RJ/m7rDW/egSSqBUEIY8JPIIZaAtFU2sEaCBeSqBYEIYzpkwKh\nlFqolHq8srL7HaH6J8UyJD0egGyHbbm9Vw9CKroKghC+9EmB6Gk/iGlD0gAYrGwP/RQv9UpksZwg\nCGFMnxSInuLKQ7gLxND2ByakW2PxIARBCDNEIFx0FWKSHIQgCGFGWArExEH9iFIOBirbQ7+rJLVM\ncxUEIcwIS4GIi45kanI1saoFgOaYVIhNan+gJKkFQQhjwlIgAGYkWh5BeXSW94MkSS0IQhgTtgIx\nIa6sbXzY0d/7QfFpgDLjhgpobe59wwRBEEKEsBWIEZGWR7CjPsV7j9qISKdIOKkra3+MIAjCCUrY\nCkSGbZHcvuZ09h+r9X5gouQhBEEIT8JWIOIarYd9gc5k4+EK7wcmSB5CEITwJHwFoqG4bVyoMzoW\niER7wT6Z6ioIQvgQdv0gXMQ1WCGmAt0ffPEgRCAEQQgjwlMg6iuIaq0zQx1DKf2oLKyiobmVuOhI\n92NlqqsgCGFKeIaYbH2oSyIyAUWLQ7O10Et1WFksJwhCmBKmAmH1oa5LsNqMbjjkJcxkbxokHoQg\nCGFEeApEheVBRNqK9HlNVEuSWhCEMCU8BaLS6iSXPGBE29i7ByE5CEEQwpPwFAibB9E/ZySxUeY2\nFFTUU1Ld6H6sVHQVBCFMCU+BsCWpo9KGMXmw1ZmuXZgpwSPE5HD0tnWCIAghQZgKhJWkJnVIWwMh\ngI2Hy92PjYqF2H5mrFtN0T5BEIQwIPwEorkBaorMWEVA8kCmDbUEwnsewt56VMJMgiCEB+EnEFUF\n1jh5EERGM32oVbF1c34lrQ6Pyq6SqBYEIQzpkwKhlFqolHq8stLLwrauqLBmMLn6UA9KiSMzORaA\nmsYW9pbUuJ8jFV0FQQhD+qRAaK0Xa61vTUlJ6fpgT2wJalcfaqWUex7CM8wk9ZgEQQhD+qRA9Ah7\ngjolp21oF4gNnonqRFlNLQhC+BF+AmFbA4FtFfX0zhLV4kEIghCGhF8119FnQ0wCpXs3kpE1oW33\nlJxUlAKtYVdRNbWNLSTGOm+P1GMSBCEMCT8PYtJlcMEf2TLlZzB0btvupNgoxmQlA+DQZjZTG5Kk\nFgQhDAk/gegEe5jJbUW1THMVBCEMEYGw0eGKaqnoKghCGCICYcNzRbXWzgVznklq7bGQThAE4QRE\nBMLG6KxkEmNMy9Hi6kYOlJq2pMQkQlScGbc0QFNtkCwUBEE4fohA2IiMUMwYZpXd+OnrW3A4NCgl\nrUcFQQg7RCA8uP2s0UQoM16xr5Snlu83G/aCfbWShxAE4cRHBMKDWbnpfHv+qLbtBz/cyfYjVTLV\nVRCEsEMEwgu3nz26rYlQU6uDO17eSGu8LJYTBCG8EIHwQnRkBA9dNY24aHN7dhZVs7bYdqvEgxAE\nIQwQgeiAUVlJ3HP++LbtzwpsU1tlLYQgCGGACEQnXDd3GPPHZgJQRj/rjZ4kqasKoXCjrKUQBCHk\nEYHoBKUUD1w+hfTEGMp1ctt+XVfi3wXLD8LD0+HxM2Dds4ExUhAEoZcQgeiCrOQ4fnvpZEptAlFe\ncsS/i+14xyy0A1j9RACsEwRB6D1EIHzgqxMHcNKksW3bteVFFFTUd/9ChRuscfFWKNsfAOsEQRB6\nBxEIH7ntgpPaxqm6ittf2kBDc2v3LmIXCICd7wXAsgDS2gz1FV0fJwhCWCAC4SNJ/TLQytRpSlb1\nbD5YzG3/WkdTi8O3CzRUQuke9307QkggGqpMfuTBUaFllyAIQUMEwlciIlC2znJpVLNkZwl3vLKB\nllYfROLIpvb7Dn0JdWUBNLIH7P4vVB4GRzOsfy7Y1giCEAKIQHQHm0BkqCoA3ttylLte22yK+nWG\nZ3gJQDtg1weBtNB/qo9aY3vfbkEQwhYRiO5gq8d0zaTEtvHr6wv4+dt5Vv8IbxRutMbpI63xjncD\naaH/1BRZ48r84NkhCELIIALRHWwexLWTE1g0e0jb9r9WHuK37+/oWCTsHsT8u63x3k+h2Y8ZUYGm\nptgaN1aanIkgCGGNCER3sHkQqq6UX18ymYumDWrb9/iyfTz8yZ7259WXQ7lzSmtkDEy4CDJGm+3m\nOti3tBeN9hG7BwHiRQiCIALRLexNg2qPERmh+MMVUzlnQnbb7oc+3sUTy/a5n2cPL2VPhKhYGHe+\ntS8Uwkx2DwJEIARBEIHoFokevakxlV8fuWY680Zb7/36ve08+fk+K9xkDy8NnGZex15g7dv1ATi6\nuaYi0LTzICRRLQjhjghEd7DlIOwlv2OjInn8+lnMybW6zt3/7nbueTOP5laHu0AMmm5ec2ZBYpYZ\n15ZA/pretLxzWpvblzAXD0IQwh6fBEIpdbtSqp8yPKWUWq+UOqe3jQs57ALhUdE1PiaSp26cxYyh\nqW37Xlx1iBueXk2rPcTkEoiISBh7rrU/mGGmWi/FB0UgBCHs8dWD+IbWugo4B8gEbgJ+12tWhSpd\ntB1NjovmxVvmsnCqlbjevnc/kZWHzEZkLGRZPSbcwkzBLLvhGV4CEQhBEHwWCOV8PR94Rmu9ybYv\nfPBIUnsjLjqShxdN4wdfGQPA5AirIF9V6jiIjLYOHnEGRDvXU5TugZJdATfZJzwT1CACIQiCzwKx\nTin1X4xAfKiUSgZ8LEJ0ApFg5RioL4eWJq+HKaX43lmjefTaGcyIOtC2/83ibJ79Yr+VvI6Oh1EL\nrBN3vNNzG1tbun+ONw+iqtC/awmCcMLgq0DcDNwNzNZa1wHRmDBTeBEZDalDnRsa9i/r9PDzJg/k\nG8Ot6qhbHLnct3gb97yZR2OLc9ZSIMNMn/8JfjMI3v1B987zJhC6Far97HshCMIJga8CcTKwU2td\noZS6DrgXCM+ltuO/Zo3zXuvy8H7leW3jzY4RgElef/WhZXy6owjGfBWcVWLJX+teE6k7OBzw+R+h\ntRHWPNm9IoDeQkwgYSZBCHN8FYhHgTql1FTgLuAg8HwgDVFKXayUekIp9VZIz5CadJk13vEONDd0\nfGxNMVQVAKCj4hk/eVbbWwdK6/jGs2u56ZU91A+a49yrYef7/tlVfQSaaqzt7qxjsHsQLrECEQhB\nCHN8FYgWbQLnFwF/0Vr/BUju4hyUUk8rpYqVUnke+89VSu1USu1RSt0NoLV+U2t9C3AjcFW3fovj\nyaDpkDbcjBurYM/HHR9rm96qBk7hoatn8cuLJtIvLqpt/5KdJfzp0CjrHH/DTGV73bcrC3w/1+5B\nZE+0XUMWywlCOOOrQFQrpX4CXA+8q5SKxOQhuuJZ4Fz7Due5fwPOAyYAVyulJtgOudf5fmiilLsX\n0VmYyWOBnFKKr5+cy5IfzufqOUNQznlg77fMbDusde9SVHNd9+0q9RCIqu4IhM2DGGzZIh6EIIQ3\nvgrEVUAjZj3EUWAw8GBXJ2mtlwGewfA5wB6t9T6tdRPwMnCRcxHe74H3tdbrff4NgoFdIHZ9AE21\n3o/ztoIayEiK5beXTuHt75zGzGFp5OsstjtM8jvS0cTS1asoruokdOUNz2513RIImweRY4XBRCAE\nIbyJ6voQ0FofVUq9AMxWSl0IrNZa+5uDGAzYYxf5wEnA94CzgRSl1Cit9WPeTlZK3QrcCpCdnc3S\npUv9MqKmpsbvcwFmJwwlse4QNNex7Y0/Upx9ertjTj6wkljneHV+M3Xl7T/vu+M0K1JiWbZzFuMx\nC+omN6zlor98yt1z4kmJ9W25yaRdq7Gt0qBo13q2R7X/PE8iW+qZ58xdOFQ0Gw7X4/Ihagp3sNbj\nHvX0vvUmYpt/iG3+EQ62+SQQSqkrMR7DUswCuUeUUj/SWr/qx2d6e+JprfXDwMNdnay1fhx4HGDW\nrFl6/vz5fpgAS5cuxd9zAVBfhyX3AzDBsZ0J83/u/n7VEVhabsbRicw57xpTXsMLZwJ1B9PgmdcB\nWBCxgbtqm/nr1kReunUu/ZNivZ7nRt5dbpvZ8a1k+/L7le2D5WYY0W8gM8+6BNb/EICklvJ296jH\n960XEdv8Q2zzj3CwzdcQ0z2YNRA3aK2/jgkT/czPz8wHhti2c4BCP68VPCZdao13f2QWztk5Yqu/\nNHBqh+LgImHoDOiXA0CqqmV2xE52F9dwzRMrKa1p7NwWR6vVb8JFlY/hoWpb/iEpy9Sbiooz241V\n0jhIEMIYXwUiQmttnyxf2o1zPVkDjFZKDVdKxQCLgLf9vFbwyBhple52NLcvttdB/qFDlHIr3ndS\nxA4AdhXVcO2TqzoXicp8aPVY1V1VCJ21QHVhT1AnZRs7UnLcry0IQlji60P+A6XUh0qpG5VSNwLv\nAl3Ox1RKvQSsAMYqpfKVUjdrrVuA7wIfAtuBf2utt/pnfpCZfLk19pzN1F2BABg0o214xdAaIpzB\nuB1Hq7n2yVWU1Xov7dFuiisYweigXpQb9gR1krP8uAiEIAj4KBBa6x9h4v5TgKnA41rrH/tw3tVa\n64Fa62itdY7W+inn/ve01mO01iO11r/uyS8QVCZeYo33fQY1zrLZWvsnELZKr4ObDvDHK6e2TYXd\ncbSa655cRbk3kfCc4urClzCTpwcBHgIhayEEIVzxOUyktX5Na/2/Wus7tdZv9KZRXaGUWqiUeryy\nMsjx8ZQcGHqyGetW2P6WGVcVWD0WYvtB+gjfrpc51hqX7uGSyZn84XJLJLYdqeK6p1ZRUechEh0K\nhA+pnRqPHARAylBrn3gQghC2dCoQSqlqpVSVl59qpVTV8TLSE631Yq31rSkpKcEywcJt0ZyZheTe\nYnQqRPiowzGJkJZrxroVSvdw2cwcHrhsSptIbC2s4qK/fcHfluzhYKlz/YU9xBRvqzjry2pqtxCT\nNw9CBEIQwpVOn1xa62StdT8vP8la637Hy8iQZsJFoJy38eCX5qHs1kFuWveul2lrKFS8HYArZg3h\n95dOadt9sLSOBz/cyRkPLmXhI8upyN9hnTN8njX2ZbGc3YNIHmBe7QJRISEmQQhXpCd1T0nKguGu\nRXIatr7hX/7Bhb3jXPG2tuGVs4fwhyumEh/tPl12W0EZiXWWEHzZajvfJ4GQJLUgCN4RgQgEbmGm\nV3soELayVMU73N66fGYOa+49mz9fNY2zx2cRHanIUSVEK9Nb4ohO529bbOsQuwoxORxQaxOIRKdA\n9Bts7auWxkGCEK6IQASC8Qshwlm7sHAD1DvLT8WlWJVffSVrnDW2eRAukmKjuHj6YJ68YTZr7/kK\nvzotru29A44BHNEZbdulR/ZT3dDc8WfVl4OjxbI12nmt6DhLLLRDGgcJQpjSJwUiZGYxuYhPg1Fn\nt98/aDpt2WVfyRiNdv2zlB+Apo4ru6YkRHN6hjVXoH/ueBxJg9q2k5uKOe+hz1i5r9T7BbxNcW27\nuISZBCHc6ZMCEVKzmFzYw0wuuhteAoiOoz5+oHNDw7GdnR9vm+I6etxU3rrzHGojTKuOGNVKQ2Ux\nVz+xkt+8t52G5lb3c0UgBEHohD4pECHJ2PMgKt5938BuzmByUptoW4fgnMnUIfYprukjSUmIJjFz\nmGWCKkVreHzZPi766xdsK7TNTvaWoHaRal8LITOZBCEcEYEIFLFJpr+0HX88CKA20XrAdykQ9kVy\nGSPNaz8rzHTWIGtR3c6iai7623Lue3srh0rrxIMQBKFTRCACiT3MFJ/u/i28G/jsQbQ02r7dKysh\nbpuFdPvsRH510UTios0/dXOr5tkvDzD/D0v4eM1m61qeHoSU2xCEsEcEIpCM+SpkTzLjmTd0P0Ht\nxE0gSnZ0fGD5ATPLCCBliDULKcUSCFVVwPUn5/Le9+cxfWhq236HhppSaxrshrJYWlod1rXFgxCE\nsMenhkGCj0TFwi1LTJE8X+sveaE+fqCZNutoNt/eG6ogzsvCdbfwku3z7OsYnPWYRmQm8fptp/D5\n7mM8uXw/y3aVkIk1C+yhlRXs3baUm07N5fqThxGbYmvZIQIhCGGJeBCBJiqmR+IAoCOioP8Ya0dH\nXoRHgroNN4GwvASlFKePyeT5b8zhwztOZ1SC1Uu7RKdSUFHP/e9uZ9HjKylqSZTGQYIQ5vRJgQi5\ndRC9QVb7mkzt8JagBneB6GA19dgByWRHWPevOT6zbbzhUAUL//oFDQlWslu8CEEIP/qkQITkOohA\n47aiugOB6NCDsD3YqwtNSQ1PWhqtNqkqgnd+fBE/Pncckc4uRcXVjaytSLSOF4HomLzX4JNf+dag\nSRD6EH1SIMICt5pM7UtuAB17EDEJVtlvR4t7vSUXrn4VAIlZxMXGcNv8kTz/jTmkJpiyIfkOq2xH\na/mh7v4G4UHRNnj1G/D5H+DTXwXbGkEIKCIQoUqmzYPwloNoqrPyCyoSUoe5v99BHqINb42CgFNH\n9eft75zGuAHJFOr+bfvf+Xx1xy1Pw5n81db4wBfBs0MQegERiFAlLddamV1TBHVl7u+X77fGqUNN\nctxOShd5CG+NgpwMzUjgtdtOoX+OLdlemc/X/rqcQ1Ue5TrCHbsXV7bPhO4E4QRBBCJUiYh0b0Hq\nmYfoKLzkwp6H6NKDyG73dmJsFNd/9dS27UHqGPnl9dy/soG/frq7fV2nLiipbuTNDQVmBfeJRNk+\na+zsAigIJwqyDiKUyRoPR5zd6Yq3Qa71wO4wQe2iyxBTJ3WYnCjbWogcZSrCNjngD//dxStrD3Pv\nBRM4Z0I2qpMFgUVVDfzjs328sOogjS0OoiIU15w0lO+fNZr+SbEdntdn8OwHXrwdsicGxxZBCDAi\nEKFMZ1Ndu/Qgugoxde5BeF5jQEQ5EwcksvWoWTtxuKye//nnOuaN7s//LZzAqKxkt1OPVNbz2NK9\nvLTmME0t1iyqFofm+RUHeX19Ad86YwQ3nzaC+Bj3Lnl9BofDPdQHUNJF9V1B6ENIiCmUsfen9kxU\nl3bhQaS0X03tRgdJajdsjYOUdvDW14fz9QkxbbOcAD7ffYxz//w5v3pnG1UNzRRU1HPvm1s444Gl\nPLfioJs42D2GmsYW/vDfXcz/wxL+veYwrQ7t3YYAsONoFTc9s5pfLN7a7dBYp1QVQEuD+76SLoor\nCkIfok96EEqphcDCUaNGBduU3sWzP7XWVn2nsm54EF2GmDrwIABSh7RNk42qLmTB0GjuvOwU/vTR\nLl5YdRCHNl7BU8v389r6fGobW2hudX/YT81J4fazR3Pm2Cw+3VHMb9/fwZ7iGgCKqhq567XNPP3F\nfu4+bxxnjMnsNGTVXfYU13DNE6vMDKydJewtqeXx62cSFx0Ar6Vsb/t9xZ3UzhKEPkaf9CDCYqEc\nmIJ5Mc7QTX259VBvrLY8gIhoU6jPE7ckdSE4PL45Vx+1xp0JhJeifWmJMfzq4km88715zBme3vZ2\nRV2zmzhMH5rKszfN5s3vnMqCcSZXcdb4bD64fR6/vXQymcmWR7HjaDU3PrOGRY+vZPV+jxlbflJQ\nUc/Xn1rlNj132a4SvvHsGuqaAtBn2zP/ADKTSTih6JMCETYo5b1HtX3mTFouRHpxBKPjIcG50E23\nunsMWvuUpAbcxafSfbHchEH9eOXWuTxy9XQGpli9sWcNS+OfN8/h9dtOYf7YrHYeQVRkBFfPGcrS\nH87njrNHk2DLQazaX8aV/1jB9U+tYuPhio7t6oLSmkauf2oVhZUmBBQdadnw5d5SbnxmDTWNPRQJ\n+7+DC5nJJJxAiECEOt4S1V0lqF10NNW1sRpa6s04Kh5i3RPMbnRR9lspxcKpg/jkB2fw56um8eq3\nTuY/3zqZeaO7DhUlxkZxx9ljWPqj+Vxz0lCiIqzjP999jIv/9gU3P7uGvILu1dyqbmjmhmdWs6/E\nJNSjIxVP3zibH33Vmja8en8ZNzy9mqqG5m5d2w27EETYRLqrJk+C0EcQgQh13BLVXgTCW4LaRT/b\nw90uEJ7eQ2cPch/7QiTERHHx9MHMyk3vdg4hKzmO31wymU9/MJ/LZuRg0wk+2VHMhY8s57Z/rWNX\nUXWX12pobuWbz60lr8C0Vo1Q8JdF05k3OpPvnDmKe8637ue6g+Vc/9RqKuv8FAn7v8Pw061xZz08\nBKEPIQIR6njzIMo66APhSUerqX2Z4tp2jePXOGhoRgJ/vHIqH/3vGSycOshNt97PO8o5Dy3j8ke/\n5J8rDlBa0z7O3+LQfPfF9aybCG95AAAgAElEQVSy5TB+c8lkzp88sG37ltNHcN9Cq87VpsMVXPvU\nSsq9lBFxODSHy+pYurOY/6w9zJoDZVS7PI7WFtOwycXY862xCIRwgtAnZzGFFW5F+3aY/IFbiKmT\nmVwdhZjsApHclUAc/8ZBIzOTeOTq6Xz3zFE89NEuPthqJdTXHixn7cFy7lu8jdNG9eeiaYM4Z+IA\nEqIjeTqviS8LLe/oJ+eNY9Gc9m1fbzx1OFGREdz7Zh4AeQVVXP3ESr51xkj2Hatlb0kNe4tr2H+s\nlsaW9pVwh6THMy+jht84jFi0JmTRnD0dVxam8uAWHn5nG4fL6jhUVkd+eT1xEa3c0Lqba+cOIz0x\npt01BSEUEYEIdZKyID7NzGJqqjYP6a5WUbvwKcTUhUAkZJg8RUs9NFYR2VLb+fEBZOyAZB67fiZ5\nBZX85ZPdfLqjuG29RKtD89muEj7bVUJs1BbGZCezpdBKOt82fyT/c0bH9+a6ucOIiYzgx69vRmsz\ni+qOVzb6ZNfhsnryK/LA+ZxfW5POjY8eZLtTIRJrD/HP5btowlovUgP88aNd/HXJHi6dkcPNp+W2\nW1woCKGGhJhCHaXcvYhDK6HOlL0gKs59vYMndg/C3xCTUm5hpriGkk4O7h0mDU7hia/PYvVPz+JX\nF01k1rA0t/cbWxxssSWyr54zlLtsCemOuHL2EP54xVS3nIcn/ZNimDM8nQsmD2TcgOS2RHqusrya\nA44B1BPHIYdpuhSlHIxQR7xer7HFwUurD3H2n5Zx0zOr+WLPMbTuvUWCgtATxIPoC2SOg4POUtI7\n3rH2pw2HiE40vqPV1L5OcW27Tg6U7gaCIxAuMpJiuf7kXK4/OZf88joWbzrCWxsL2HHUSl5fMHkg\n9188yedE+aUzckiKjeKJz/eRmhDDyMwkRmYmMsL5mprgHg5qbGllT3ENMR+9B84qG0XRg4l0KA5H\nDWOow9yfO6c5aBo3naHpCQxKjefJxZ/zRWlsW/IcYMnOEpbsLGHcgGQWzR7CySP7MzoriYjOFEsQ\njiN9UiDCZiW1C3uievdH1rizKa4AyfbOckfMYrmIyO55EODmQcQ2Bk8g7OSkJXDb/JHcNn8ku4uq\n+e+2IgoO7ue+q6a1dcXzlXMmDuCciQN8OjY2KpKJg1Ig0rqH37/iq3xv/Hmoj1fCF2sB+GpmOUy1\n7v/Jg6K4++rTWL2/jCeX7+fj7UW4HIcdR6u5b7FZ45KaEM2sYemcNDydOcPTmTioH1GR4ugLwaFP\nCoTWejGweNasWbcE25bjgl0gmm05gPROZjCBqaWU0B/qjpkFXNVHjVfhSx0mO7ZEdTA9iI4YnZ3M\n6Oxkli7NJybqOD1MPfJASin3Kcle1kIopThpRAYnjcjgwLFanvliP/9em0+9rT5URV0zH28v4uPt\n5t8oISaSmcPSuPakYZw7yTcRE4RAIV9N+gL2B4+drjwI8B5m6k6SGjw8COm7TGszlB+0tl1CbV/1\n3kVV19z+ifziokms+MkCfvG1iZw7cYDX2U11Ta18vvsY3/rXOh76aJfkK4TjSp/0IMKOxAzzILd/\n84fOp7i66DcYjmwy46p8cMzw6Eed2fU1gpykDjkqDhmPDEwYLybBjPuPBRSgrZpMUZ33vEhNiOGG\nU3K54ZRctNbsLall9f4y1hwoY/X+Mgoq6tuO/csnuzla2cD9l0wiWsJOwnFABKKvkDmuvUB0NsXV\nRT8PD6KuzHq4xad1+QADQjIHEVQ6KnUSk2Dav1YcNPf42G4YMMnnyyqlGJWVxKisJK45yazfOFxW\nx0/f2MLnu43n9srawxRVN/C3a2aQGCt/vkLvIl9D+gr2qa4A0YmQ7ENM2nOqa42PVVztuAlEmVlF\nHM645R888kBZnfTw8IMh6Qk8feNsLpth/Rss3VnCosdXUlItVWOF3kUEoq9gj2+DeTD5MpXTXiqj\nKr/7CWowXoZTTBQOMyMqnOmsWGKmPQ8RmJIb0ZER/OGKKXxvgRVS3FJQyaWPfsG+kpqAfIYgeEME\noq/g6UF0VoPJjmeIqbsJahduNZkO+37eiUhnK9ntAhHAqq5KKX5wzlh+fcmktoV9h8vquezRL1l3\nsDxgnyMIdiSI2VfI9PQgfMg/gJcQUzfXQLhIyYGCdc7rHJ+aTCFLZx5EVuA9CDvXnjSM7OQ4vvvS\nehqaHZTXNXPNEys5fUwmSbFRJMVGkRgbRVJsJInOcUZiDNOGpJKR5EO+SehVtNas3FfGB3lHmDg4\nhUunDw7pdS4iEH2FuH6mtlKV8+HsywwmcBeImqPuK6p9DTGBe9E+exXTcKOlyeZBKbOa3Y4fM5m6\ny9kTsnnplrnc/NxaymqbaGxx8NG2oi7PG5mZyJzh6czONYvwctISAmpXIGlqcfD8igNs2d3E4PHV\njM72vW5VfVMrizcV8smOIqYNSeOmU3MD02K2B7Q6NB/kHeXxZXvZlG+VhXnq8/3ce+F45o32YTZh\nEBCB6EsMnQt5r5rx4Bm+nRMVa6ay1paAdsCRzdZ7Sd1YeJVpq21UlOf7eSca5QfMfQTjVUXHub8f\nkwBpw6zjujmTyVemD03jtdtO4RvPrmH/Md8KKO4tqWVvSS0vrTYCNygljtnD08loaWZ2Y0vIzIoq\nqmrg2y+sbwudvfXQMmYOS+Oq2UO4cMpAEmK827m7qJoXVh3itfX5VDeYiRQfbi3ipdWH+PmFEzhr\nfPvuhr1NfVMrr647zJPL93OwtK7d+zuLqrn+qdUsGJfFT88fz6ispONqX1eExv8IwTe+8ktTXXXQ\nNPfZMl3Rb7C19uGoXSC64UEMmGyNj27x/bwTjc5mMLnIHGd5WSU7ekUgAIb3T+S/d57O2gPlVNY3\nUdPYSm1jCzXOH9f4wLFathRUuvULByisbOCtjcaj/M/uT7hsZg7XnzyMkZldP6Tqm1pZvucYaw+U\nkRQbxdCMBIakJzA0PYGMxBi/H8RrD5Rx2wvr283QWnewnHUHy/nl4m18bdogFs0ewuTBKTS1Ovhw\naxH/Wnmww17mh8rq+ObzazlzbCY/XziR4f0Tu7TjYGkt249UUVrbRGlNE2W1Tc5xY9u4qamJYXnL\nGZgSx8CUeAalxjEgJZ5BKXGkJcaweFMhz6846NYTHSAmKoIFY7NYtruEuiYz5fzTHcUs21XCdXOH\nccfZo9vVALOjtaaqoYXG5lay+sV1eFwgEIHoS6QMhvMf8OO8HDjiLGXdbPsW050cROZ4UJFmfn/Z\nPtO2tLNWpScqvrR7zRwHuz4w415uPxodGcHJIzO6PK6huZUNhypYc8Aswlt3sLzt4QRQ3djCs18e\n4NkvD3DaqP5cf/IwzhqX5RYfL6lu5NMdRXy0rYjPdx/z2isDTHmQoelGMHIzEjhrfDYnDe+806DW\nmn+tPMgvFm+jxVnSPULB+PQIdlXoNnGraWzhxVWHeHHVIcYNSKakupFSL82eXJ/72vp8KpwdA5fs\nLOGLPcv45rzhfHfBKDdPpK6phRV7S1nmLCF/wMu3fW9szq9kc75vLXFT4qO5fu4wbjgll8zkWIqr\nGnjww528uj4frU3Dq2e/PMAbGwr43oJRDE6N52hVA0erGiiqdL5WNXK0soH65lYWjMvi6Rtn+/TZ\n/tInBSLsivX1FHsewk53BCI6zoSZik1ROYq2mpBXuOFLL44Ar4UIBHHRkZw8MqNNTFpaHWw7UsWX\ne0t59rOdHK2zvIvle46xfM8xBqfGty3Y+3h7ERsPV+BLpY+6plZ2HK1uq7L7xOf7GZmZyNVzhnLZ\njBzSPEqKNDS3cu+beby6zpr8kJYQzV+vmUFzfh6TZp3M6+vzeXnN4bY+44BbFV+AyAjFOROyufak\nYZwyMoOICMV3zxzFg//dyUurD6E1NLU6+PvSvbyxoYA7vzKGiromPttVwpr95TS1ehe8njI4NZ5v\nzhvOlbOGuIXxsvrF8eAVU7nhlFx+9c62tk6IlfXN3P9u118sjlQ29Iq9dvqkQIRdsb6e4q1nRESU\nWUndHQZMtgTi6JbwFAhfPQgXISIQnkRFRjAlJ5UpOamMcRwiOmcSz684yCfbi3B+gaegop4HP+y4\nptTorCQWjDNhyoOlpnveobI6ahrbL6TcW1LL/e9u54EPdnLe5AFcM2coc4anU1jZwG3/Wuf2LXzy\n4BQevW4GOWkJLM2H/kmx3Hr6SG6ZN4K1B8t5efVh3t1SSEOzeaAPTInj6jlDuWr2ELI9Qi5piTH8\n5pLJXD17KD9/O48NhyoA83C969XNdISrSOKglHjSk2LISIwhIymG9MRYMhJjSE+MYcWKFQwbP40j\nlQ0cqaynsMK8HqlsoKiqgZy0BL5+8jAumDyw05lKkwan8PKtc/lw61F+894ODpV17b0kxEQSH937\ns5/6pEAI3cSbQCRmdd5LwhsDJsPmV8w4XPMQZfuscUceRP8xuM1kau79b3o9IUIp5o3OZN7oTPLL\n63hx1SFeXnO4Xew8QsHs3HS+MiGbs8dnk+sllq+1pqKuuU0sVuwr5e2NhW2i0dTq4K2Nhby1sZCR\nmYmU1zW7fc5lM3L49SWTvM46UkoxO9fMwvr5wgms2HuMpNho5o5I73Kq6OScFF771im8tj6f33+w\ng2M17cNS4wYkc8aYTM4Yk8nM3DRiozqf+ZQRH8Gs3PROj/EVpRTnThrImeOy+OeKgyzZWUx8dCTZ\n/eIY0C+O7BTzOjDFjJNjo45Lwl0EIhxI8SIQ3UlQuwj3RHVzg7UGREVAWq734zxnMjmbLfUFctIS\nuOvccXz/rNG8t+UIH+QdJTY6kgXjMpk/JqtdeMgTpRRpiTGkJcYwdUgqC6cO4p7zx7N4UyEvrT7k\nNsVzry1cFBWh+PnCCVw/d5hPD76U+GjOnTSwW79bRITiillD+OqkATz8sWlhO35QP84Yk8npozMZ\nkNK7CV9fiI2K5JvzRvDNeT4uhO1lRCDCAW8eRHfyDy6ybQJRvM3UZIo8Af4L1ZbC9rch9zToP7rj\n48r3A874S8oQiOrkYZk53jaTaSfQP0DGHh/ioiO5dEYOl9pqQPlLYmwUi+YMZdGcoeQVVPLi6kO8\ntaGAWmeSPDM5lr9fO4PZAfo23hX94qK598IJ3HvhhK4PDnNOgL9uoUuSB9IW8nDhjweRmEFDbAZx\njaXQ0gCle9rXiOqLvHYz7Ftimit9bx3Ep3o/zpf8g4vMsbDrfTMu3g6R8wJjax9n0uAUfnPJZO45\nfzzvbj7CkcoGrp4zpNenawr+EbprvIXAERXTXhD88SCAmiSb63sihJkaq2H/Z2Zcdww2vdzxsb7M\nYHIRgjOZQonE2CiunD2E288eLeIQwohAhAueU139FghbaYmjHc8C6TMUbrBWRgOseZIO53J2y4MI\n/ZlMgtAVIhDhgmcewp8QE54CcQJ4EPlr3bdLd8P+Zd6P9WUGk4u2mUzmvIjW9rNmBCHUEYEIF1I8\nko0B8SC2dPxtu6/gKRBgvAhvdMeDcM1kAtAO4usL/LNPEIKICES40C7E5J8H0RCXDTHOEht1x6D6\naOcnhDJaQ4EXgdjxrnvVW4CmOqh27lORprVoV2RaeYjE2kM9MFQQgoMIRLjQLsTknweBinAvPteX\nw0yVh63+GLH9YOgpZqxbYd1z7sfaw0tpwyAyuuvr22Z4JdaGeZMloU8iAhEu2AUiJglie1BWONsu\nEH04UW0PLw2aDifdam2vexZam63t7sxgcmFLVCfUiQch9D1EIMKFjFGm/pJr3BNOlBXVdoHImQ3j\nLrQ8q5qjsOMd6/3u5B9cZIoHIfRtRCDChaRMuOBPMPocOO/3PbvWiSIQ9vxDziwTNpp5o7VvzVPW\n2B8PwjaTKb7+aMjXZBIET0QgwomZN8C1/+l5FdYsZ28IsHpD9JT8dbD091B1pOfX8oWWJijcaG0P\nnmVeZ9xg/W4HPodi5xqGUlsOIsPHOjkxCW31mhR9qyaTIEAfFQil1EKl1OOVlb416hACTHS889sx\ngIaibT27Xk0JPH8RLP0NPHMuNPnWQrNHFG2BVmfXstRhxsMCU9hw3PnWcWudXoQ/HgS4L5grlgVz\nQt+iTwqE1nqx1vrWlJSUYJsSvriFmXqYqN70IjQ5vZDyA7DkNz27ni/kr7PGOR5duWZ/0xpvfMlM\n5XXNdoqINoX6fMVecmPzy31/3YgQVvRJgRBCgEDlIbRuP6V05d+hYJ334wNF/hprnDPL/b3hZ0CG\ns6prUzUs/Z31Xlpu9yrYTriIthXVez6Gra/7Y60gBAURCME/7AJRlOf/dQ4sdw/fgKmN9Pb33aeZ\nBpoCjxlMdpRy9yLW2wTM1xlMLgZNgzm2xofv/xjqy7t3DUEIEiIQgn+4CcRW0xvCH+wP3zHnQnSC\n85p58MVf/LevM2pLrYVvkTHuv4uLqYssW+zF/LqTf3Cx4Gc0xmQ4P7sEPvp5968hCEFABELwj8T+\nkOws39HS0N4L8IW6Mtj2trV95k/hzHus7c8egGO9MPPHHr4aMAWiYtsfE58Kk69ov9/XGUx24vqx\ne7RtEd76543nJAghjgiE4D89zUNsetmaSTRoOgycCid9y4zBvPf298Hh6Pga/uCWf5jd8XH2MJML\nfzwI4FjmXLMQz8XiO2RdhBDyiEAI/tOTmUxau4eXZtxgXiOj4GuPWKu+D30J657pmZ2eeC6Q64iB\nUyBnjvu+7uYg7Jz/oFXosHQ3LP+T/9cShOOACITgPz3xIA6vthrpRCfC5Mvdr3vq7db2R//Xvrqq\nvzgcHlNcOxEIcPciImOhXw96NPcbBGf/n7X9+Z+c/aoFITQRgRD8xy4QRzZ3b46/3XuYdCnEJru/\nf/pdVs2opmp49weBWUNQugcanQssE/qbRXKdMfFi6D/WjMeeBxE9/JOZdbMV1nI0w+LbAx9CE4QA\nIQIh+E/acFMZFkxvCNdisq6or4A823qAmTe1PyY6DhY+bG3vfA+2vem/rS488w9KdX58VCx84wO4\nYTFc1kEjoe4QEQEL/2ILoa1wF0tBCCFEIAT/iYjwKP3tY5hpy3+gpd6MsyfB4Bnej8s91V083vuR\nmfnUE9zyDzN9OychHYaf7lsPCF/Intg+hNaXGy8JJywiEELP6G6i2ltyurNv8V/5BSQPNOPaEvjw\np/7Z6cLXGUy9zek/gnTnlNnGSrOAThBCDBEIoWd0N1FduME6LioOplzZ+fFxKXDBH63tTS/Bzve7\nbyeYIoBthQUVDOrAczkeRMfDhX+2tre96R52E4QQQARC6BndFQi79zDxErMgrSvGXeC+aG3x7f6F\nmgo3mnaiYKqsxvXr/jUCyYgzYNq11vbi202xQkEIEUQghJ5h7w1Ruhcaazo+trEGtrxqbbvWPvjC\neQ/Yur0Vwft3dd9Wt/CSj/mH3ubc31ozqRqr4NWbe7cGlSB0AxEIoWd49oYo7qQ3RN5r0OQUkP5j\nu9e4KCHdPSSz5T/uZTp8obMCfcEiLgUuf8aa1VSwFpb8Org2CYITEQih5/iaqLaHl2Z2kZz2xrjz\nYerV1vY7d0LtMd/Pt/egHtzFArnjSc5MWPAza3v5Q7D30+DZIwhORCCEnuNLHuLoFqtIXmQMTFnk\n32ed+ztrVlPdMXjvh76dV1kA1c52ptGJ7o18QoFTvg8jF1jbr/8P1BQHzx5BQARCCAQdCURjDRz4\nAr542CRgXYxfCIkZ/n1WfKqp1eRi6xu+zf6x5x8Gz4CISP8+v7eIiIBL/gGJWWa7thje+B9ZZR0s\nHK3QUBn2HQC70RpLEDrAszfEW9+BgvWm1pL28oDrTnLaG6O/AtOvhw3/NNvv/gByT+v8HF8L9AWT\npCy49B/wz0vM9t5PYcUj7ovqQo2WRjN92NEKjhbbj3M7MtqsuO9piZLeRGso32+mYBesN69HNpl8\nWWQsJA8wdbSSB5gS987t1PJCOJJm8khxqRDbL7R/Tz8QgRB6jqs3RHWh6Q2x4V8dHzviTMid1/PP\n/OqvYe8SqMqH+jKTj8j2Up7bRajmHzwZuQBOvQO+cCbkP/klDDvN/1lXDVVGtB0tZoqvdhivRDva\ntpOqi4D53bxupVkBvvEFaG3q/NjMcTDvh6bm1vHy3BprzEO+sdqUjW9tNmLW2ggtTcbm+nI4stEI\nQkdd/loboeKg+fFgGsAm+x5lpk7HpRpPNyHDzLxLynK+2saJmUY8tevfQjt/nNtoUBFmhqBS5r6p\nSOtVRTjH3czjdRMRCCEw5MyE7R4VV1WEeTgMngGDZ5qFaQOnBuY/dVwKXPSI9W17xztkqTHAme2P\nbW02ayDabA1hgQBYcK9pKFSw1jzYX70JvvW5+Z19pbUZVj1m+mk3dTL1GJgFULEYzrnflAHpil0f\nmn4W1T5W2C3ZAa9/E5b+Fub9wCyO7KxsicNhJjvsW8LwfXmQWmhmymWM6njdTH0FHFoJB5fDwS/d\n17z4S1Sc+cLjM9oIZ0OlV0EJONmT4bbebTzVJwVCKbUQWDhq1KhgmyK4WPBzE1aIjDFiMHimEYPY\npN77zJELYNY3YO3TAIzZ9Q94qwSyJpgkdNYE842taKtV+ylliAkRhDKR0XD5U/DYPLM2ouIgvHI9\nnH1fx3Wr7OxbCu/dBce6UUp876fw2GkmdHfmPZCc3f6YujL44G7Y/Ir7/tgUY3NElPMn0hpX5kNz\nrTmubC+89W347Hdw2v/CtGusbn61pbBvCez+CPZ+YsqqAMMADtnWziRlG7HoP9o0b6rMh4NfOHNf\nPcgXxKWaeztouvkiM3iGCSs1VkN1kRHD6qOm7Hz1UagupKJgL6lxGHFqqDRVh48nxyGc1ScFQmu9\nGFg8a9asW7o8WDg+ZI6Bq186/p/7lV/Cno+h4hBRrbVWXsJFfLr7t85Q9x5cpOWaqq+vOosV7v8M\nnjjTCO/sW8wq9Og493Mq8+HDe9pXvU0daoSxLSwRYYUpWpvQ+z5D4QxtrH/OrFc59Q44+TsQ4+zL\nvfVNM2PM+eAGTLn0C/4AEy7u2CusKzOezMrHrDLrFYfgnTtg2YMw/mtmAkHBOnx6wNcUmZ8Dn3dx\noDLeUL9B5ktLVKx5tY+j4y0PN224998hNtn89G//ZXTj0qXMnz/f2tHa4vQgKoxouCoc1xRBTYnz\ntdi81h4zHo6KMLYq5fx3cf6AWxjQhAVbzZcw1z7V++G6PikQgtBGbLKZ/fPPSy0vwU59mflxEcr5\nB08mXQqF6+FL26ytgnXm57/3wIyvGw8qKRtW/M08cJvrrGNjkmD+3aaNaychnbXvPMvs8restRdN\nNbDkftPJ74y7jABvX+x+0uQrzZTjrmajJaSbXuMnfwdWPw4r/m79e1QVwKpHOzgvA0aexcFKzbCk\nZtObvHSP1aLWExVh+ovnngbDToVhJ0N8Wue2BZrIKHM//J2h112OwwwrEQih7zPsFPjBdja9/xxT\nB8Wa1dzF282PPf4eGQNjzg2enf5wzv3mG/rqJ2Dr61ZCuK7ULKj74i9mamyNR7nwKVcZ78qHcFpt\nUi5c+Abs/hj+ey+UbDdvVBW4T08GMxnhwodgbDfvY1yKqWB70m0mJPjlI2YqrwsVYVa3j/oKjDoL\nBk6DiAj2L13KMNe3dEer8T6O7YZju4xgxKUYQRh6UvdyNCcCvZygBhEI4UQhPo3y9Gkwd761T2uo\nPGyEovyAiS17CRWEPDmzzM8598OG52HN02b2FphQg10csiaasM+wU7r/OaPPhhHzTZhuya/dw0lg\npief86uePYhjk+DU78OcW2DTy2Z66aDp5nO7+sYfEQnpw83PmHP8t0HwGREI4cRFKRN/Tx0abEsC\nQ1KmmQV0yu2w6wMTstn/mXkvNgUW3GNamkb24M86Mgpm3WR6hC//s/mM5AFw/oPmIR4oouPN5wgh\njQiEIPQ1IqNg/IXmp2SXmcc/6iyzHiVQxCbDWT8z+QMVcVzCGULoIQIhCH2ZzDHmp7cItZIkwnHl\nxFoXLgiCIAQMEQhBEATBKyIQgiAIgldEIARBEASviEAIgiAIXhGBEARBELwiAiEIgiB4Rek+3FJP\nKVUC+Ft4vT/QjY73xxWxzT/ENv8Q2/yjL9s2TGud2dVF+rRA9ASl1FqtdUiW9hTb/ENs8w+xzT/C\nwTYJMQmCIAheEYEQBEEQvBLOAvF4sA3oBLHNP8Q2/xDb/OOEty1scxCCIAhC54SzByEIgiB0QtgJ\nhFLqXKXUTqXUHqXU3cG2xxOl1AGl1Bal1Eal1Nog2/K0UqpYKZVn25eulPpIKbXb+XqcG/92att9\nSqkC573bqJQ6Pwh2DVFKLVFKbVdKbVVK3e7cH/T71oltQb9vTjvilFKrlVKbnPb9wrl/uFJqlfPe\nvaKUigkh255VSu233btpx9s2px2RSqkNSql3nNuBuWda67D5ASKBvcAIIAbYBEwItl0eNh4A+gfb\nDqctpwMzgDzbvgeAu53ju4Hfh5Bt9wE/DPI9GwjMcI6TgV3AhFC4b53YFvT75rRJAUnOcTSwCpgL\n/BtY5Nz/GHBbCNn2LHB5CNy7/wVeBN5xbgfknoWbBzEH2KO13qe1bgJeBi4Ksk0hi9Z6GVDmsfsi\n4Dnn+Dng4uNqlJMObAs6WusjWuv1znE1sB0YTAjct05sCwm0oca5Ge380cAC4FXn/mDdu45sCzpK\nqRzgAuBJ57YiQPcs3ARiMHDYtp1PCP2BONHAf5VS65RStwbbGC9ka62PgHngAFlBtseT7yqlNjtD\nUEEJf7lQSuUC0zHfNkPqvnnYBiFy35yhko1AMfARxuOv0Fq3OA8J2t+sp21aa9e9+7Xz3j2klIoN\ngml/Bu4CHM7tDAJ0z8JNILw11g2JbwE2TtVazwDOA76jlDo92Ab1IR4FRgLTgCPAH4NliFIqCXgN\nuENrXRUsO7zhxbaQuW9a61at9TQgB+Pxj/d22PG1yvmhHrYppSYBPwHGAbOBdODHx9MmpdSFQLHW\nep19t5dD/bpn4SYQ+a5fxZgAAANzSURBVMAQ23YOUBgkW7yitS50vhYDb2D+SEKJIqXUQADna3GQ\n7WlDa13k/CN2AE8QpHunlIrGPIBf0Fq/7twdEvfNm22hct/saK0rgKWYOH+qUirK+VbQ/2Zttp3r\nDNtprXUj8AzH/96dCnxNKXUAEzJfgPEoAnLPwk0g1gCjnRn+GGAR8HaQbWpDKZWolEp2jYFzgLzO\nzzruvA3c4BzfALwVRFvccD2AnVxCEO6dM/77FLBda/0n21tBv28d2RYK981pR6ZSKtU5jgfOxuRJ\nlgCXOw8L1r3zZtsOm+grTJz/uN47rfVPtNY5WutczPPsU631tQTqngU7+368f4DzMbM39gL3BNse\nD9tGYGZWbQK2Bts+4CVMyKEZ433djIlvfgLsdr6mh5Bt/wS2AJsxD+SBQbDrNIw7vxnY6Pw5PxTu\nWye2Bf2+Oe2bAmxw2pEH/Ny5fwSwGtgD/AeIDSHbPnXeuzzgXzhnOgXp/s3HmsUUkHsmK6kFQRAE\nr4RbiEkQBEHwEREIQRAEwSsiEIIgCIJXRCAEQRAEr4hACIIgCF4RgRCEIKCUmu+qvCkIoYoIhCAI\nguAVEQhB6ASl1HXOPgAblVL/cBZsq1FK/VEptV4p9YlSKtN57DSl1Epn4bY3XEXvlFKjlFIfO3sJ\nrFdKjXRePkkp9apSaodS6gXnalxBCBlEIAShA5RS44GrMAUUpwGtwLVAIrBem6KKnwH/5zzleeDH\nWuspmNW1rv0vAH/TWk8FTsGsAAdTTfUOTE+GEZi6OoIQMkR1fYgghC1nATOBNc4v9/GYInsO4BXn\nMf8CXldKpQCpWuvPnPufA/7jrK01WGv9BoDWugHAeb3VWut85/ZGIBdY3vu/liD4hgiEIHSMAp7T\nWv/EbadSP/M4rrN6NZ2FjRpt41bk71EIMSTEJAgd8wlwuVIqC9r6Sg/D/N24KmVeAyzXWlcC5Uqp\nec791wOfadNvIV8pdbHzGrFKqYTj+lsIgp/INxZB6ACt9Tal1L2YDn8RmMqx3wFqgYlKqXVAJSZP\nAaas8mNOAdgH3OTcfz3wD6XUL53XuOI4/hqC4DdSzVUQuolSqkZrnRRsOwSht5EQkyAIguAV8SAE\nQRAEr4gHIQiCIHhFBEIQBEHwigiEIAiC4BURCEEQBMErIhCCIAiCV0QgBEEQBK/8P6BICIccqkVI\nAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x20085d3af28>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(h.history['loss'], linewidth=3, label='train')\n",
    "plt.plot(h.history['val_loss'], linewidth=3, label='valid')\n",
    "plt.grid()\n",
    "plt.legend()\n",
    "plt.xlabel('epoch')\n",
    "plt.ylabel('loss')\n",
    "# plt.ylim(1e-3, 1e-2)\n",
    "plt.yscale('log')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
